{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU",
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "d1e3eeb3694541779f598a1d603807ca": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "VBoxModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "VBoxView",
                        "_dom_classes": [],
                        "_model_name": "VBoxModel",
                        "_view_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_view_count": null,
                        "_view_module_version": "1.5.0",
                        "box_style": "",
                        "layout": "IPY_MODEL_641c7a789a524b46a27dd2642f9bde5b",
                        "_model_module": "@jupyter-widgets/controls",
                        "children": [
                            "IPY_MODEL_548a0801a77948fc90c35fb287c56001",
                            "IPY_MODEL_6d0374cc603b4ed0b39310fb7e36eac9"
                        ]
                    }
                },
                "641c7a789a524b46a27dd2642f9bde5b": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_view_name": "LayoutView",
                        "grid_template_rows": null,
                        "right": null,
                        "justify_content": null,
                        "_view_module": "@jupyter-widgets/base",
                        "overflow": null,
                        "_model_module_version": "1.2.0",
                        "_view_count": null,
                        "flex_flow": null,
                        "width": null,
                        "min_width": null,
                        "border": null,
                        "align_items": null,
                        "bottom": null,
                        "_model_module": "@jupyter-widgets/base",
                        "top": null,
                        "grid_column": null,
                        "overflow_y": null,
                        "overflow_x": null,
                        "grid_auto_flow": null,
                        "grid_area": null,
                        "grid_template_columns": null,
                        "flex": null,
                        "_model_name": "LayoutModel",
                        "justify_items": null,
                        "grid_row": null,
                        "max_height": null,
                        "align_content": null,
                        "visibility": null,
                        "align_self": null,
                        "height": null,
                        "min_height": null,
                        "padding": null,
                        "grid_auto_rows": null,
                        "grid_gap": null,
                        "max_width": null,
                        "order": null,
                        "_view_module_version": "1.2.0",
                        "grid_template_areas": null,
                        "object_position": null,
                        "object_fit": null,
                        "grid_auto_columns": null,
                        "margin": null,
                        "display": null,
                        "left": null
                    }
                },
                "548a0801a77948fc90c35fb287c56001": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "LabelModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "LabelView",
                        "style": "IPY_MODEL_79437690512b40f7bb681ed8cc48c459",
                        "_dom_classes": [],
                        "description": "",
                        "_model_name": "LabelModel",
                        "placeholder": "\u200b",
                        "_view_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
                        "_view_count": null,
                        "_view_module_version": "1.5.0",
                        "description_tooltip": null,
                        "_model_module": "@jupyter-widgets/controls",
                        "layout": "IPY_MODEL_884d3ec7f06b45ce8ea1a8ca1fdfd53c"
                    }
                },
                "6d0374cc603b4ed0b39310fb7e36eac9": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "FloatProgressModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "ProgressView",
                        "style": "IPY_MODEL_9e3e56d0ae88415e831c66f0fea30b25",
                        "_dom_classes": [],
                        "description": "",
                        "_model_name": "FloatProgressModel",
                        "bar_style": "",
                        "max": 1,
                        "_view_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "value": 1,
                        "_view_count": null,
                        "_view_module_version": "1.5.0",
                        "orientation": "horizontal",
                        "min": 0,
                        "description_tooltip": null,
                        "_model_module": "@jupyter-widgets/controls",
                        "layout": "IPY_MODEL_e681c1729fa24ab99ccdd4f18c17ef98"
                    }
                },
                "79437690512b40f7bb681ed8cc48c459": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "DescriptionStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "StyleView",
                        "_model_name": "DescriptionStyleModel",
                        "description_width": "",
                        "_view_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.5.0",
                        "_view_count": null,
                        "_view_module_version": "1.2.0",
                        "_model_module": "@jupyter-widgets/controls"
                    }
                },
                "884d3ec7f06b45ce8ea1a8ca1fdfd53c": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_view_name": "LayoutView",
                        "grid_template_rows": null,
                        "right": null,
                        "justify_content": null,
                        "_view_module": "@jupyter-widgets/base",
                        "overflow": null,
                        "_model_module_version": "1.2.0",
                        "_view_count": null,
                        "flex_flow": null,
                        "width": null,
                        "min_width": null,
                        "border": null,
                        "align_items": null,
                        "bottom": null,
                        "_model_module": "@jupyter-widgets/base",
                        "top": null,
                        "grid_column": null,
                        "overflow_y": null,
                        "overflow_x": null,
                        "grid_auto_flow": null,
                        "grid_area": null,
                        "grid_template_columns": null,
                        "flex": null,
                        "_model_name": "LayoutModel",
                        "justify_items": null,
                        "grid_row": null,
                        "max_height": null,
                        "align_content": null,
                        "visibility": null,
                        "align_self": null,
                        "height": null,
                        "min_height": null,
                        "padding": null,
                        "grid_auto_rows": null,
                        "grid_gap": null,
                        "max_width": null,
                        "order": null,
                        "_view_module_version": "1.2.0",
                        "grid_template_areas": null,
                        "object_position": null,
                        "object_fit": null,
                        "grid_auto_columns": null,
                        "margin": null,
                        "display": null,
                        "left": null
                    }
                },
                "9e3e56d0ae88415e831c66f0fea30b25": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "ProgressStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "StyleView",
                        "_model_name": "ProgressStyleModel",
                        "description_width": "",
                        "_view_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.5.0",
                        "_view_count": null,
                        "_view_module_version": "1.2.0",
                        "bar_color": null,
                        "_model_module": "@jupyter-widgets/controls"
                    }
                },
                "e681c1729fa24ab99ccdd4f18c17ef98": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_view_name": "LayoutView",
                        "grid_template_rows": null,
                        "right": null,
                        "justify_content": null,
                        "_view_module": "@jupyter-widgets/base",
                        "overflow": null,
                        "_model_module_version": "1.2.0",
                        "_view_count": null,
                        "flex_flow": null,
                        "width": null,
                        "min_width": null,
                        "border": null,
                        "align_items": null,
                        "bottom": null,
                        "_model_module": "@jupyter-widgets/base",
                        "top": null,
                        "grid_column": null,
                        "overflow_y": null,
                        "overflow_x": null,
                        "grid_auto_flow": null,
                        "grid_area": null,
                        "grid_template_columns": null,
                        "flex": null,
                        "_model_name": "LayoutModel",
                        "justify_items": null,
                        "grid_row": null,
                        "max_height": null,
                        "align_content": null,
                        "visibility": null,
                        "align_self": null,
                        "height": null,
                        "min_height": null,
                        "padding": null,
                        "grid_auto_rows": null,
                        "grid_gap": null,
                        "max_width": null,
                        "order": null,
                        "_view_module_version": "1.2.0",
                        "grid_template_areas": null,
                        "object_position": null,
                        "object_fit": null,
                        "grid_auto_columns": null,
                        "margin": null,
                        "display": null,
                        "left": null
                    }
                },
                "5843c42b4144467cb8998bfe0dff9362": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "VBoxModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "VBoxView",
                        "_dom_classes": [],
                        "_model_name": "VBoxModel",
                        "_view_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_view_count": null,
                        "_view_module_version": "1.5.0",
                        "box_style": "",
                        "layout": "IPY_MODEL_303e07bac95d4e0abc99917278d85eff",
                        "_model_module": "@jupyter-widgets/controls",
                        "children": [
                            "IPY_MODEL_619bc1ac055749ddb2f3dac918b3dfc6",
                            "IPY_MODEL_647e24e645e443ea904a5fd3b9569a27"
                        ]
                    }
                },
                "303e07bac95d4e0abc99917278d85eff": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_view_name": "LayoutView",
                        "grid_template_rows": null,
                        "right": null,
                        "justify_content": null,
                        "_view_module": "@jupyter-widgets/base",
                        "overflow": null,
                        "_model_module_version": "1.2.0",
                        "_view_count": null,
                        "flex_flow": null,
                        "width": null,
                        "min_width": null,
                        "border": null,
                        "align_items": null,
                        "bottom": null,
                        "_model_module": "@jupyter-widgets/base",
                        "top": null,
                        "grid_column": null,
                        "overflow_y": null,
                        "overflow_x": null,
                        "grid_auto_flow": null,
                        "grid_area": null,
                        "grid_template_columns": null,
                        "flex": null,
                        "_model_name": "LayoutModel",
                        "justify_items": null,
                        "grid_row": null,
                        "max_height": null,
                        "align_content": null,
                        "visibility": null,
                        "align_self": null,
                        "height": null,
                        "min_height": null,
                        "padding": null,
                        "grid_auto_rows": null,
                        "grid_gap": null,
                        "max_width": null,
                        "order": null,
                        "_view_module_version": "1.2.0",
                        "grid_template_areas": null,
                        "object_position": null,
                        "object_fit": null,
                        "grid_auto_columns": null,
                        "margin": null,
                        "display": null,
                        "left": null
                    }
                },
                "619bc1ac055749ddb2f3dac918b3dfc6": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "LabelModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "LabelView",
                        "style": "IPY_MODEL_465de250d2974c87afdb552930f4c9cc",
                        "_dom_classes": [],
                        "description": "",
                        "_model_name": "LabelModel",
                        "placeholder": "\u200b",
                        "_view_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "value": " 0.32MB of 0.32MB uploaded (0.00MB deduped)\r",
                        "_view_count": null,
                        "_view_module_version": "1.5.0",
                        "description_tooltip": null,
                        "_model_module": "@jupyter-widgets/controls",
                        "layout": "IPY_MODEL_9d5adb0381e54144a33beacfd735fc39"
                    }
                },
                "647e24e645e443ea904a5fd3b9569a27": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "FloatProgressModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "ProgressView",
                        "style": "IPY_MODEL_eb65f34e50df4842bfb83ea9b1aa667d",
                        "_dom_classes": [],
                        "description": "",
                        "_model_name": "FloatProgressModel",
                        "bar_style": "",
                        "max": 1,
                        "_view_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "value": 1,
                        "_view_count": null,
                        "_view_module_version": "1.5.0",
                        "orientation": "horizontal",
                        "min": 0,
                        "description_tooltip": null,
                        "_model_module": "@jupyter-widgets/controls",
                        "layout": "IPY_MODEL_9b3f8592095547e89485ef4be20bbf71"
                    }
                },
                "465de250d2974c87afdb552930f4c9cc": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "DescriptionStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "StyleView",
                        "_model_name": "DescriptionStyleModel",
                        "description_width": "",
                        "_view_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.5.0",
                        "_view_count": null,
                        "_view_module_version": "1.2.0",
                        "_model_module": "@jupyter-widgets/controls"
                    }
                },
                "9d5adb0381e54144a33beacfd735fc39": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_view_name": "LayoutView",
                        "grid_template_rows": null,
                        "right": null,
                        "justify_content": null,
                        "_view_module": "@jupyter-widgets/base",
                        "overflow": null,
                        "_model_module_version": "1.2.0",
                        "_view_count": null,
                        "flex_flow": null,
                        "width": null,
                        "min_width": null,
                        "border": null,
                        "align_items": null,
                        "bottom": null,
                        "_model_module": "@jupyter-widgets/base",
                        "top": null,
                        "grid_column": null,
                        "overflow_y": null,
                        "overflow_x": null,
                        "grid_auto_flow": null,
                        "grid_area": null,
                        "grid_template_columns": null,
                        "flex": null,
                        "_model_name": "LayoutModel",
                        "justify_items": null,
                        "grid_row": null,
                        "max_height": null,
                        "align_content": null,
                        "visibility": null,
                        "align_self": null,
                        "height": null,
                        "min_height": null,
                        "padding": null,
                        "grid_auto_rows": null,
                        "grid_gap": null,
                        "max_width": null,
                        "order": null,
                        "_view_module_version": "1.2.0",
                        "grid_template_areas": null,
                        "object_position": null,
                        "object_fit": null,
                        "grid_auto_columns": null,
                        "margin": null,
                        "display": null,
                        "left": null
                    }
                },
                "eb65f34e50df4842bfb83ea9b1aa667d": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "ProgressStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_view_name": "StyleView",
                        "_model_name": "ProgressStyleModel",
                        "description_width": "",
                        "_view_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.5.0",
                        "_view_count": null,
                        "_view_module_version": "1.2.0",
                        "bar_color": null,
                        "_model_module": "@jupyter-widgets/controls"
                    }
                },
                "9b3f8592095547e89485ef4be20bbf71": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_view_name": "LayoutView",
                        "grid_template_rows": null,
                        "right": null,
                        "justify_content": null,
                        "_view_module": "@jupyter-widgets/base",
                        "overflow": null,
                        "_model_module_version": "1.2.0",
                        "_view_count": null,
                        "flex_flow": null,
                        "width": null,
                        "min_width": null,
                        "border": null,
                        "align_items": null,
                        "bottom": null,
                        "_model_module": "@jupyter-widgets/base",
                        "top": null,
                        "grid_column": null,
                        "overflow_y": null,
                        "overflow_x": null,
                        "grid_auto_flow": null,
                        "grid_area": null,
                        "grid_template_columns": null,
                        "flex": null,
                        "_model_name": "LayoutModel",
                        "justify_items": null,
                        "grid_row": null,
                        "max_height": null,
                        "align_content": null,
                        "visibility": null,
                        "align_self": null,
                        "height": null,
                        "min_height": null,
                        "padding": null,
                        "grid_auto_rows": null,
                        "grid_gap": null,
                        "max_width": null,
                        "order": null,
                        "_view_module_version": "1.2.0",
                        "grid_template_areas": null,
                        "object_position": null,
                        "object_fit": null,
                        "grid_auto_columns": null,
                        "margin": null,
                        "display": null,
                        "left": null
                    }
                }
            }
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Mh3KayG0qaJw"
            },
            "source": [
                "Notebook created by [V\u00edctor Campos](https://imatge.upc.edu/web/people/victor-campos) for UPC ETSETB AAL 2019\n",
                "\n",
                "Updates:\n",
                "\n",
                "[Xavier Gir\u00f3](https://imatge.upc.edu/web/people/xavier-giro) - UPC ETSETB AAL 2019\n",
                "\n",
                "[Juan Jos\u00e9 Nieto](https://www.linkedin.com/in/juan-jose-nieto-salas/) - UPC School - AIDL Spring 2021"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "0spTu6Dawi2S"
            },
            "source": [
                "# DQN example in PyTorch\n",
                "\n",
                "This notebook is adapted from the [official DQN tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html). Unlike the tutorial, we will use the standard observation instead of the RGB images."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "hIYC7IeEwrlt"
            },
            "source": [
                "## Installing dependencies\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "!pip install gym wandb pygame --quiet\n",
                "\n",
                "# install utilities for rendering OpenAI Gym videos in Colab\n",
                "!apt-get -qq install -y xvfb x11-utils\n",
                "!pip install pyvirtualdisplay==0.2.* \\\n",
                "             PyOpenGL==3.1.* \\\n",
                "             PyOpenGL-accelerate==3.1.* \\\n",
                "             --quiet\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "RzOcEmlJw6gb"
            },
            "source": [
                "## Setting up the environment"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import base64\n",
                "import glob\n",
                "import io\n",
                "import os\n",
                "import math\n",
                "import timeit\n",
                "import warnings\n",
                "\n",
                "from IPython.display import HTML\n",
                "from IPython.display import display"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import gym\n",
                "import wandb\n",
                "import random\n",
                "\n",
                "import numpy as np\n",
                "from random import randint\n",
                "from datetime import datetime\n",
                "from collections import namedtuple\n",
                "\n",
                "import matplotlib.pyplot as plt"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "source": [
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# starting a fake screen in the background\n",
                "#  in order to render videos\n",
                "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
                "os.environ[\"DISPLAY\"] = \":1\"\n",
                "\n",
                "# utility to get video file from directory\n",
                "def get_video_filename(dir=\"video\"):\n",
                "  glob_mp4 = os.path.join(dir, \"*.mp4\") \n",
                "  mp4list = glob.glob(glob_mp4)\n",
                "  assert len(mp4list) > 0, \"couldnt find video files\"\n",
                "  return mp4list[-1]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "cBKofZ4KrG8Z"
            },
            "source": [
                "## Visualize a random policy in the environment\n",
                "\n",
                "Our goal is to train an agent that is capable of solving the CartPole problem, where a pole is attached to a cart moving along a horizontal track. The agent can interact with the environment by applying a force (+1/-1) to the cart. The episode is terminated whenever the pole is more than 15 degrees from vertical or the cart goes out of bounds in the horizontal axis. The agent receives +1 reward for each timestep under the desired conditions.\n",
                "\n",
                "We can visualize what a random policy would do in this environment:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
                "\n",
                "env = gym.wrappers.RecordVideo(env, \"./video\")\n",
                "\n",
                "ob, done, total_rew = env.reset(return_info=True), False, 0\n",
                "\n",
                "while not done:\n",
                "  env.render()\n",
                "  \n",
                "  ac = env.action_space.sample()\n",
                "  \n",
                "  ob, rew, done, info = env.step(ac)\n",
                "  \n",
                "  total_rew += rew\n",
                "  \n",
                "print('Cumulative reward:', total_rew)\n",
                "  \n",
                "env.close()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "1SJmW9MxiZiB"
            },
            "source": [
                "# Log in to your Wandb account"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "wandb.login()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "-AxNWAK5iwTD"
            },
            "source": [
                "# Visualize random policy in Wandb"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "PROJECT = \"AIDL-Spring-DRL\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "wandb.init(project=PROJECT)\n",
                "wandb.run.name = 'cartpole_random_agent'\n",
                "mp4 = get_video_filename()\n",
                "wandb.log({\"Video eval\": wandb.Video(mp4, fps=4, format=\"mp4\")})\n",
                "wandb.finish()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "5XIB8KMAw1HL"
            },
            "source": [
                "## Replay memory\n",
                "\n",
                "The buffer will be a FIFO queue: when full, oldest experiences are removed to make room for new transitions.\n",
                "\n",
                "**Exercise #1.** Implement the pointer to the next position to be filled in the replay memory, which corresponds to a FIFO queue.\n",
                "(TIP: remember the [modulus % operator](https://python-reference.readthedocs.io/en/latest/docs/operators/modulus.html))."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "Transition = namedtuple(\n",
                "    'Transition', ('state', 'action', 'next_state', 'reward'))\n",
                "\n",
                "\n",
                "class ReplayMemory(object):\n",
                "    def __init__(self, capacity):\n",
                "        self.capacity = capacity\n",
                "        self.memory = []\n",
                "        self.position = 0\n",
                "\n",
                "    def push(self, *args):\n",
                "        \"\"\"Saves a transition.\"\"\"\n",
                "        if len(self.memory) < self.capacity:\n",
                "            self.memory.append(None)\n",
                "        self.memory[self.position] = Transition(*args)\n",
                "        \n",
                "        # TODO: Update the pointer to the next position in the replay memory\n",
                "        self.position = ...\n",
                "\n",
                "    def sample(self, batch_size):\n",
                "        return random.sample(self.memory, batch_size)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.memory)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "HeZXG6VHygrD"
            },
            "source": [
                "## Model definition\n",
                "\n",
                "Now we will define our policy, parameterized by a feedforward neural network."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "class DQN(nn.Module):\n",
                "    def __init__(self, inputs, outputs, hidden_size=128):\n",
                "        super(DQN, self).__init__()\n",
                "        self.affine1 = nn.Linear(inputs, hidden_size)\n",
                "        self.affine2 = nn.Linear(hidden_size, outputs)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.affine1(x)\n",
                "        x = F.relu(x)\n",
                "        x = self.affine2(x)\n",
                "        return x"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "0T02F2uyndg5"
            },
            "source": [
                "## Functions for collecting experience and updating the policy\n",
                "\n",
                "**Exercise #2.** Complete eps_greedy policy to facilitate the exploration.\n",
                "\n",
                "**Exercise #3.** Complete with `policy_net` or `target_net` the `TODO_net` in the code.\n",
                "\n",
                "**Exercise #4.** Compute the TD target."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def compute_eps_threshold(step, eps_start, eps_end, eps_decay):\n",
                "  return eps_end + (eps_start - eps_end) * math.exp(-1. * step / eps_decay)\n",
                "\n",
                "\n",
                "def select_action(policy, state, eps_greedy_threshold, n_actions):\n",
                "    # TODO: Select action using an epsilon-greedy strategy\n",
                "    if random.random() ...\n",
                "\n",
                "      with torch.no_grad():\n",
                "            # t.max(1) will return largest column value of each row.\n",
                "            # second column on max result is index of where max element was\n",
                "            # found, so we pick action with the larger expected reward.\n",
                "            \n",
                "            action = policy(state).max(1)[1].view(1,1)\n",
                "            \n",
                "    else:\n",
                "      action = torch.tensor(\n",
                "          [[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
                "    return action\n",
                "\n",
                "    \n",
                "def train(policy_net, target_net, optimizer, memory, batch_size, gamma):\n",
                "    if len(memory) < batch_size:\n",
                "        return 0\n",
                "    transitions = memory.sample(batch_size)\n",
                "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
                "    # detailed explanation). This converts batch-array of Transitions\n",
                "    # to Transition of batch-arrays.\n",
                "    batch = Transition(*zip(*transitions))\n",
                "\n",
                "    # Compute a mask of non-final states and concatenate the batch elements\n",
                "    # (a final state would've been the one after which simulation ended)\n",
                "    non_final_mask = torch.tensor(\n",
                "        tuple(map(lambda s: s is not None, batch.next_state)), \n",
                "        device=device, \n",
                "        dtype=torch.bool)\n",
                "    \n",
                "    non_final_next_states = torch.cat(\n",
                "        [s for s in batch.next_state if s is not None])\n",
                "    \n",
                "    state_batch = torch.cat(batch.state)\n",
                "    action_batch = torch.cat(batch.action)\n",
                "    reward_batch = torch.cat(batch.reward)\n",
                "\n",
                "    # TODO: Compute Q(s_t, a) - the model computes Q(s_t) for all a, then we select \n",
                "    #\u00a0the columns of actions taken. These are the actions which would've been \n",
                "    # taken for each batch state according to policy_net\n",
                "    state_action_values = TODO_net(state_batch).gather(1, action_batch)\n",
                "\n",
                "    next_state_values = torch.zeros(batch_size, device=device)\n",
                "\n",
                "    # TODO : Compute Q(s_{t+1}) for all next states.\n",
                "    # Expected values of actions for non_final_next_states are computed based\n",
                "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
                "    # This is merged based on the mask, such that we'll have either the expected\n",
                "    # state value or 0 in case the state was final.\n",
                "    # Note the call to detach() on Q(s_{t+1}), which prevents gradient flow\n",
                "    next_state_values[non_final_mask] = TODO_net(non_final_next_states).max(1)[0].detach()\n",
                "\n",
                "\n",
                "    # TODO: Compute targets for Q values: y_t = r_t + gamma*max(Q_{t+1})\n",
                "    expected_state_action_values = TODO\n",
                "\n",
                "    # Compute Huber loss between predicted Q values and targets y\n",
                "    loss = F.smooth_l1_loss(\n",
                "        state_action_values, expected_state_action_values.unsqueeze(1))\n",
                "\n",
                "    # Take an SGD step\n",
                "    optimizer.zero_grad()\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "\n",
                "    return loss.item()\n",
                "    \n",
                "    \n",
                "def test(env, policy, video_path='./video', render=False):\n",
                "    state, ep_reward, done = env.reset(), 0, False\n",
                "    while not done:\n",
                "        if render:\n",
                "          env.render()\n",
                "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
                "        action = select_action(policy_net, state, 0., 1)\n",
                "        state, reward, done, info = env.step(action.item())\n",
                "        ep_reward += reward\n",
                "\n",
                "    env.close()\n",
                "    mp4 = get_video_filename(video_path)\n",
                "    wandb.log({\"Video eval\": wandb.Video(mp4, fps=4, format=\"mp4\")})\n",
                "    return ep_reward"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "wr4pSznznosA"
            },
            "source": [
                "## Training the agent"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "hparams = {\n",
                "    'gamma' : 0.99,             # discount factor\n",
                "    'log_interval' : 25,        # controls how often we log progress, in episodes\n",
                "    'num_steps': 60000,         # number of steps to train on\n",
                "    'batch_size': 256,          # batch size for optimization\n",
                "    'lr' : 1e-4,                # learning rate\n",
                "    'eps_start': 1.0,           # initial value for epsilon (in epsilon-greedy)\n",
                "    'eps_end': 0.1,             # final value for epsilon (in epsilon-greedy)\n",
                "    'eps_decay': 20000,         # length of epsilon decay, in env steps\n",
                "    'target_update': 1000,      # how often to update target net, in env steps\n",
                "    'replay_size': 10000,       # replay memory size\n",
                "}\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Create environment\n",
                "env_name = 'CartPole-v1'\n",
                "env = gym.make(env_name, render_mode=\"rgb_array\", new_step_api=True)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Get number of actions from gym action space\n",
                "n_inputs = env.observation_space.shape[0]\n",
                "n_actions = env.action_space.n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "9_oxnUdB5yif"
            },
            "source": [
                "**Exercise #5.** Complete the call to `memory_push`."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Fix random seed (for reproducibility)\n",
                "seed = 543\n",
                "torch.manual_seed(seed)\n",
                "torch.cuda.manual_seed(seed)\n",
                "\n",
                "# Initialize wandb run\n",
                "wandb.finish() # execute to avoid overlapping runnings (advice: later remove duplicates in wandb)\n",
                "wandb.init(project=PROJECT, config=hparams)\n",
                "wandb.run.name = 'dqn_cartpole_train_0'\n",
                "\n",
                "\n",
                "# Initialize policy and target networks\n",
                "policy_net = DQN(n_inputs, n_actions).to(device)\n",
                "target_net = DQN(n_inputs, n_actions).to(device)\n",
                "target_net.load_state_dict(policy_net.state_dict())\n",
                "target_net.eval()\n",
                "\n",
                "optimizer = torch.optim.Adam(policy_net.parameters(), lr=hparams['lr'])\n",
                "memory = ReplayMemory(hparams['replay_size'])\n",
                "\n",
                "print(f\"Target reward: {env.spec.reward_threshold}\")\n",
                "step_count = 0\n",
                "running_reward = 0\n",
                "\n",
                "ep_rew_history = []\n",
                "i_episode, ep_reward = 0, -float('inf')\n",
                "while step_count < hparams['num_steps']:\n",
                "    # Initialize the environment and state\n",
                "    state, done = env.reset(), False\n",
                "    state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
                "    reward_episode = 0\n",
                "    losses = []\n",
                "    while not done:\n",
                "        # Select an action\n",
                "        eps_greedy_threshold = compute_eps_threshold(\n",
                "            step_count, hparams['eps_start'], hparams['eps_end'], hparams['eps_decay'])\n",
                "        action = select_action(\n",
                "            policy_net, state, eps_greedy_threshold, n_actions)\n",
                "\n",
                "        # Perform action in env\n",
                "        next_state, reward, terminated, truncated, info = env.step(action.item())\n",
                "        done = terminated or truncated\n",
                "\n",
                "        # Bookkeeping\n",
                "        if done:\n",
                "            # train() treats states as terminal when next_state is None\n",
                "            next_state = None\n",
                "        else:\n",
                "            next_state = torch.from_numpy(next_state).float().unsqueeze(0).to(device)\n",
                "        \n",
                "        reward = torch.tensor([reward], device=device)\n",
                "        step_count += 1\n",
                "\n",
                "        # TODO: Store the transition in memory\n",
                "        memory.TODO\n",
                "\n",
                "        # Move to the next state\n",
                "        state = next_state\n",
                "\n",
                "        # Reward episode\n",
                "        reward_episode += reward.item()\n",
                "\n",
                "        # Perform one step of the optimization (on the policy network)\n",
                "        loss = train(policy_net, target_net, optimizer, memory, hparams['batch_size'], hparams['gamma'])\n",
                "        losses.append(loss)\n",
                "        # Update the target network, copying all weights and biases in DQN\n",
                "        if step_count % hparams['target_update'] == 0:\n",
                "            target_net.load_state_dict(policy_net.state_dict())\n",
                "\n",
                "    i_episode += 1\n",
                "\n",
                "    running_reward = 0.05 * reward_episode + (1 - 0.05) * running_reward\n",
                "    wandb.log(\n",
                "        {\n",
                "        'loss': np.mean(losses),\n",
                "        'running_reward': running_reward,\n",
                "        'ep_reward': reward_episode,\n",
                "        'epsilon': eps_greedy_threshold # log last epsilon of the episode\n",
                "        })\n",
                "    \n",
                "    # Evaluate greedy policy\n",
                "    if i_episode % hparams['log_interval'] == 0:\n",
                "        video_path = datetime.now().isoformat(timespec=\"seconds\")\n",
                "        test_env = gym.wrappers.RecordVideo(env, f\"./{video_path}\")\n",
                "        ep_reward = test(test_env, policy_net, video_path=video_path)\n",
                "        ep_rew_history.append(ep_reward)\n",
                "        print(f'Episode {i_episode}\\tSteps: {step_count/1000:.2f}k\\tEval reward: {ep_reward}\\tRunning reward: {running_reward:.2f}')\n",
                "\n",
                "wandb.finish()\n",
                "print(f\"Finished training! Eval reward: {ep_reward}\")\n",
                "if not os.path.exists('checkpoints'):\n",
                "    os.makedirs('checkpoints')\n",
                "torch.save(policy_net.state_dict(), f'checkpoints/dqn-{env_name}.pt')"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "plt.plot(np.arange(len(ep_rew_history)), ep_rew_history)\n",
                "plt.xlabel('Episode')\n",
                "plt.ylabel('Reward')"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                ""
            ],
            "execution_count": null,
            "outputs": []
        }
    ]
}
