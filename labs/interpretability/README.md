# Interpretability of a Convolutional Neural Network

[![Jupyter Notebook](https://img.shields.io/badge/Jupyter-Notebook-green.svg)](./lab_interpretability_todo.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/telecombcn-dl/labs-all/blob/main/labs/interpretability/lab_interpretability_todo.ipynb)

Notebook created by [Daniel Fojo](https://www.linkedin.com/in/daniel-fojo/) and [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro) for the [Postgraduate course in artificial intelligence with deep learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) ([UPC School](https://www.talent.upc.edu/ing/), 2019). Updated by [Albert Mosella-Montoro](https://www.albertmosellamontoro.com/) in 2020 and for [Paula G. Duran](https://www.linkedin.com/in/paulagd-1995/) in 2022.

Minor contributions by [Gerard I. GÃ¡llego](https://www.linkedin.com/in/gerard-gallego/) and [Pol Caselles](https://www.linkedin.com/in/pcaselles/) during 2022.

Based on previous versions by [Amaia Salvador](https://www.linkedin.com/in/amaiasalvador/) ([Persontyle](https://github.com/telecombcn-dl/2017-persontyle), 2017) and [Daniel Fojo](https://www.linkedin.com/in/daniel-fojo/) ([Barcelona Technology School](https://barcelonatechnologyschool.com/), 2019).
