{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## Language Modeling I: BERT Text Classification\n",
                "\n",
                "In this section, we will explore the powerful pretrained language model **BERT** (Bidirectional Encoder Representations from Transformers) and apply it to the task of text classification.\n",
                "\n",
                "Through hands-on examples, we will see how it can be fine-tuned for specific tasks such as text classification.\n",
                "\n",
                "Let's start!\n",
                "\n",
                "![image.png](data:image/png;base64,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)"
            ],
            "metadata": {
                "id": "jcAd6JyKVMVO"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's install some libraries!\n",
                "\n",
                "\n",
                "> **Important**: There is a bug with the newest version of `evaluate`, to prevent it, we need to downgrade the library to the `0.4.0` version.\n"
            ],
            "metadata": {
                "id": "G-WML_lJQztM"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "! pip install transformers datasets accelerate evaluate==0.4.0"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data Loading\n",
                "\n",
                "For this text classification task, we will be using the **TeCla** dataset, which is specifically designed for multi-class text classification tasks in Catalan. TeCla is a large-scale, publicly available corpus that contains news articles from various domains, making it a great resource for training and evaluating language models on real-world text data.\n",
                "\n",
                "### Dataset Overview\n",
                "\n",
                "The **TeCla** dataset is hosted on Hugging Face under the identifier: `projecte-aina/tecla`. You can access it directly from the following link: [TeCla Dataset](https://huggingface.co/datasets/projecte-aina/tecla).\n",
                "\n",
                "The current version of the dataset, **TeCla 2.0**, contains a total of **113,376 news articles** that have been carefully labeled for multi-class text classification. These articles are classified into a hierarchical class structure, with both **coarse-grained** and **fine-grained** categories.\n",
                "\n",
                "- **Coarse-grained classes**: These represent high-level topics under which the articles are classified. There are four main coarse-grained categories:\n",
                "  1. Politics\n",
                "  2. Economy\n",
                "  3. Society\n",
                "  4. Culture\n",
                "  \n",
                "- **Fine-grained classes**: Each of the coarse-grained categories includes a set of more specific, fine-grained sub-categories. The dataset has a total of **53 fine-grained categories** that provide more detailed classification labels.\n",
                "\n",
                "This hierarchical structure allows for both broad and granular classification, making it a versatile dataset for a variety of text classification challenges. The fine-grained labels enable more specific classification, which can be especially useful when we want to fine-tune the model to recognize nuanced distinctions in different types of news articles.\n",
                "\n",
                "To get started with the dataset, we will load the TeCla data from Hugging Face using the `datasets` library.\n"
            ],
            "metadata": {
                "id": "7xpzm2A06WWN"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the necessary function to load datasets from the 'datasets' library\n",
                "from datasets import load_dataset\n",
                "\n",
                "# Define the name of the dataset to be loaded.\n",
                "# This dataset is hosted on Hugging Face Hub under the name \"projecte-aina/tecla\"\n",
                "dataset_name = \"projecte-aina/tecla\"\n",
                "\n",
                "# Load the specified dataset into a variable named 'tecla'.\n",
                "# This function downloads the dataset from Hugging Face Hub and prepares it for use.\n",
                "tecla = load_dataset(dataset_name)\n",
                "\n",
                "# Display the basic information about the loaded dataset 'tecla'.\n",
                "# This shows its structure, splits, and features, giving an overview of the dataset.\n",
                "tecla"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Explore the fields of the datasets for 10 random examples taken from the `test` split"
            ],
            "metadata": {
                "id": "DS29hf_PO6Gd"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import random\n",
                "\n",
                "# Get a random sample of 10 data points from the 'test' split of the dataset\n",
                "tecla_test_random_sample = tecla[\"test\"].shuffle(seed=42).select(range(10))\n",
                "\n",
                "# Iterate through each data point in the sample\n",
                "for example in tecla_test_random_sample:\n",
                "    # Print all the fields (keys) and their corresponding values for each data point\n",
                "    for field, value in example.items():\n",
                "        print(f\"{field}: {value}\")\n",
                "    print(\"-\" * 20)  # Print a separator between data points"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Zero-Shot Classification with a Pretrained Model\n",
                "\n",
                "Before fine-tuning, it is useful to explore zero-shot classification to understand how transformers perform without task-specific training. Zero-shot classification allows a model to classify text into categories it has never seen during training. This is possible using models trained for Natural Language Inference (NLI), such as `facebook/bart-large-mnli`. The `facebook/bart-large-mnli` model was specifically trained on datasets designed for NLI tasks, where the objective is to determine whether a given hypothesis can be inferred, contradicted, or is neutral with respect to a premise.\n",
                "\n",
                "In zero-shot classification using a fine-tuned NLI model:\n",
                "1. **Premise and Hypothesis Construction:** The input text to be classified is treated as the *premise*, while each candidate label is rephrased into a natural language *hypothesis* (e.g., \"The text is about sports.\").\n",
                "2. **Inference Calculation:** The model predicts the probability that the hypothesis is entailed by the premise. If the hypothesis is highly probable, the model considers the label as likely for the input text.\n",
                "3. **Label Scoring:** The model provides a score for each candidate label, and the label with the highest score is chosen as the predicted class.\n",
                "\n",
                "**Recommendation:** To speed up inference and reduce computational cost, consider using only `label1` as the primary label candidate during testing.\n",
                "\n"
            ],
            "metadata": {
                "id": "NGRgzZu2_qRk"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Zero-shot classification using pre-trained model\n",
                "# TODO: Choose a model from the HF Models Hub that is best suited for handling Catalan sentence: https://huggingface.co/models.\n",
                "# Hint: Search among fine-tuned models suitable for zero-shot text classification that may have trained on Catalan or at least multilingual data.\n",
                "model_name =\n",
                "\n",
                "classifier = pipeline(\"zero-shot-classification\", model=model_name, device=0)\n",
                "\n",
                "text = tecla[\"test\"][1][\"sentence\"]\n",
                "label = tecla[\"test\"][1][\"label1\"]\n",
                "labels = tecla[\"test\"].unique(\"label1\")\n",
                "\n",
                "# TODO: Apply the classifier to get predictions\n",
                "prediction =\n",
                "\n",
                "# Inspect the predictoin object and understand it\n",
                "prediction"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Extract the prediction values and take the maximum value as the prediction.\n"
            ],
            "metadata": {
                "id": "zaCIYMLOp4oW"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# TODO: Get the prediction with the highest score as the predicted label\n",
                "# Hint: Extract the index of the maximum score\n",
                "max_score =\n",
                "max_score_index =\n",
                "\n",
                "print(\"Sentence:\", text)\n",
                "print(\"Predicted Label:\", prediction[\"labels\"][max_score_index])\n",
                "print(\"Label:\", label)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Fine-Tuning\n",
                "\n",
                "In this section, we will demonstrate how to fine-tune a pretrained language model for the specific task of text classification. Fine-tuning involves adapting a general-purpose language model to perform well on a particular task by training it further on a dataset that is relevant to that task.\n",
                "\n",
                "For this demonstration, we will use the **Catalan BERTa-v2** model, which is a variant of the BERT model specifically trained on Catalan text. The model is built on the **RoBERTa** architecture, which is an optimized version of BERT that removes the Next Sentence Prediction task and trains on more data for longer periods of time. The Catalan BERTa-v2 model is designed to work with the Catalan language, making it well-suited for applications involving text written in Catalan.\n",
                "\n",
                "The specific model we are using is available on Hugging Face under the identifier: [projecte-aina/roberta-base-ca-v2](https://huggingface.co/projecte-aina/roberta-base-ca-v2). This model is pretrained on a large corpus of Catalan text, making it a great starting point for our task.\n",
                "\n",
                "Fine-tuning this model for text classification will allow us to leverage its learned representations of Catalan text, adapting it to classify new text into predefined categories. We will walk through the steps to load the pretrained model, prepare the dataset, and perform the fine-tuning process to train it for classification tasks.\n",
                "\n",
                "By fine-tuning a model like BERTa-v2, we can significantly improve the model's performance on domain-specific tasks with relatively small amounts of task-specific data, all while benefiting from the power of a large, general-purpose language model.\n"
            ],
            "metadata": {
                "id": "L4ldPt75EJco"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data Preparation\n",
                "\n",
                "### Input Preparation: Tokenization, Truncation, and Padding\n",
                "\n",
                "Before feeding the text into the model, we must preprocess it. This ensures that the input format aligns with the model's expectations and maintains consistency with the way it was originally trained. To do this, we load the tokenizer for the [projecte-aina/roberta-base-ca-v2](https://huggingface.co/projecte-aina/roberta-base-ca-v2) model, which will perform the necessary preprocessing steps. We use the `AutoTokenizer` class from Hugging Face, which automatically loads the correct tokenizer for the model.\n",
                "\n",
                "We will apply the following steps to a specific example to observe their effects:  \n",
                "- **Tokenization**: The text is split into subwords, which are converted into a list of indices (numbers). During training, these indices are transformed into tensors (high-dimensional arrays), which are the numerical representation that the model uses to process the text.  \n",
                "- **Truncation**: The text is truncated to ensure it does not exceed the maximum input length of `roberta-base-ca-v2` (512 tokens). If the text exceeds this length, it is cut off to ensure the token limit is not exceeded.  \n",
                "- **Padding**: Shorter texts are padded with special tokens called `<pad>`. This ensures that all texts in a batch have the same length, which improves efficiency in computation during training and inference.\n",
                "\n",
                "This process ensures that the texts are properly prepared to be fed into the model in an efficient and consistent manner, maintaining the features that the model learned during its initial training."
            ],
            "metadata": {
                "id": "D3xF4dwYxRzd"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Load the tokenizer for the pre-trained model.\n",
                "# The tokenizer is used to convert text into numerical tokens that can be processed by the model.\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "# Load the tokenizer for the pre-trained model \"projecte-aina/roberta-base-ca-v2\".\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"projecte-aina/roberta-base-ca-v2\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's apply the tokenizer using its *default configuration* and inspect the results.\n",
                "\n",
                "After tokenizing the text, you will encounter the following fields in the output:\n",
                "\n",
                "- **`input_ids`**: A list of token indices representing the tokenized text. Each index corresponds to a token from the model's vocabulary.\n",
                "- **`attention_mask`**: A list of binary values (1s and 0s) indicating whether a token should be attended to. Tokens with a value of `1` are actual content tokens that the model should focus on, while tokens with a value of `0` are padding tokens, which are ignored during processing.\n",
                "\n",
                "Let's check these fields to understand the structure of the tokenized input and how the model will process the text.\n"
            ],
            "metadata": {
                "id": "a5xWgVlHOr_D"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Tokenize a sentence from the dataset\n",
                "text = tecla[\"test\"][1][\"sentence\"]\n",
                "example_tokenized = tokenizer(text)\n",
                "\n",
                "print(example_tokenized)\n",
                "print(len(example_tokenized[\"input_ids\"]))"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Note**: the output of the previous cell should have raises a warning:\n",
                "\n",
                "```\n",
                "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
                "```\n",
                "\n",
                "This indicates the the text is longer than the maximum model lenght, that is the default length used to pretrain the model.\n",
                "\n",
                "\n",
                "Now, apply the tokenizer to perform *truncation to max length at 10 and padding*. Notice the difference with the default configuration!"
            ],
            "metadata": {
                "id": "TV_mBfKhZe0t"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "text = tecla[\"test\"][1][\"sentence\"]\n",
                "\n",
                "# TODO: apply padding and trucantion to maximum lenght at 10.\n",
                "# Hint: look at the arguments of the tokenizer.\n",
                "example_tokenized =\n",
                "\n",
                "print(example_tokenized)\n",
                "print(len(example_tokenized[\"input_ids\"]))\n"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Once we have the token indexes, we can always decode back the original text. Note that, by default, the tokenizer adds the special tokens required by the RoBERTa model, that are:\n",
                "\n",
                "Show the special tokens of the RoBERTa model:\n",
                "\n",
                "- `bos_token`: `<s>` (Beginning of sentence token)  \n",
                "- `eos_token`: `</s>` (End of sentence token)  \n",
                "- `unk_token`: `<unk>` (Unknown token)  \n",
                "- `sep_token`: `</s>` (Separator token)  \n",
                "- `pad_token`: `<pad>` (Padding token)  \n",
                "- `cls_token`: `<s>` (Classification token)  \n",
                "- `mask_token`: `<mask>` (Mask token)\n",
                "\n",
                "\n",
                "We can decide to decode the original text with or without such special tokens."
            ],
            "metadata": {
                "id": "7LNNGovgb_bC"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Decode original text with special tokens\n",
                "tokenizer.decode(example_tokenized['input_ids'])"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Decode original text without special tokens\n",
                "tokenizer.decode(example_tokenized[\"input_ids\"], skip_special_tokens=True)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's apply all the preprocessing steps discussed earlier to the entire dataset using a preprocessing function and the `map` method from the `datasets` library. To accelerate the process, you can set `batched=True`, which enables the `map` method to process multiple elements simultaneously, significantly improving efficiency. For a deeper understanding of the available arguments and their usage, refer to the official documentation of the `map` method."
            ],
            "metadata": {
                "id": "NRuFrEWKQHBn"
            }
        },
        {
            "source": [
                "def preprocess(example):\n",
                "  \"\"\"\n",
                "  Preprocesses a single example by tokenizing the \"sentence\" using the pre-trained tokenizer.\n",
                "\n",
                "  Args:\n",
                "    example: A dictionary containing the sentence to be preprocessed.\n",
                "\n",
                "  Returns:\n",
                "    A dictionary containing the tokenized input IDs, attention mask, and token type IDs.\n",
                "  \"\"\"\n",
                "  # Tokenize the sentence in the example using the pre-trained tokenizer.\n",
                "  # Truncate the sentence if it exceeds the maximum length (512 tokens).\n",
                "  # Pad the sentence if it is shorter than the maximum length.\n",
                "  return tokenizer(example[\"sentence\"], truncation=True, padding=True, max_length=512)\n",
                "\n",
                "# Apply the preprocess function to the \"tecla\" dataset.\n",
                "# The batched=True argument ensures that the preprocess function is applied to the dataset in batches, which can significantly improve performance.\n",
                "tokenized_tecla = tecla.map(preprocess, batched=True)\n",
                "\n",
                "# Show the result\n",
                "tokenized_tecla"
            ],
            "cell_type": "code",
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Label Preparation\n",
                "\n",
                "Next, we need to prepare the labels to ensure they are compatible with the model. Since transformer models expect numerical labels rather than string-based ones, we must convert the labels into integers.\n",
                "\n",
                "To achieve this, we will create a **mapping** between the label names and their corresponding numerical IDs using two dictionaries:  \n",
                "\n",
                "- **`label2id`**: Maps each label name to a unique integer identifier.  \n",
                "- **`id2label`**: Performs the reverse mapping, converting numerical IDs back to their original label names.  \n",
                "\n",
                "This dual mapping is essential for both training and inference:  \n",
                "- During **training**, the model will use `label2id` to process the numerical representation of the labels.  \n",
                "- During **inference**, the model can convert predicted IDs back into human-readable label names using `id2label`.  \n",
                "\n",
                "Let\u2019s implement the conversion process to prepare the dataset for training."
            ],
            "metadata": {
                "id": "GG2nUncLaGwQ"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# We use the labels from the \"train\" split\n",
                "labels = tecla[\"train\"].unique(\"label1\")\n",
                "\n",
                "# TODO: Create label-to-id and id-to-label mapping using python dictionary\n",
                "label2id =\n",
                "id2label =\n",
                "\n",
                "# Check the mapping\n",
                "print(label2id)\n",
                "print(id2label)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create a label mapping function to use with the `map` method, like before\n"
            ],
            "metadata": {
                "id": "9TvR5VICcY1e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def convert_label_to_int(example):\n",
                "    \"\"\"\n",
                "    Converts the labels in an example from string format to integer format.\n",
                "\n",
                "    Args:\n",
                "        example: A dictionary containing the labels to be converted.\n",
                "\n",
                "    Returns:\n",
                "        A dictionary containing the converted labels.\n",
                "    \"\"\"\n",
                "    # Convert the 'label1' key in the example to integers using the label2id dictionary.\n",
                "    # This ensures that the labels are in a numerical format that can be used by the model.\n",
                "    example['label1'] = [label2id[label] for label in example['label1']]\n",
                "    return example\n",
                "\n",
                "# Apply the convert_label_to_int function to the tokenized_tecla dataset.\n",
                "# This converts the labels in the dataset from string to integer format.\n",
                "# batched=True ensures that the function is applied in batches, improving performance.\n",
                "# desc provides a description of the operation for progress tracking.\n",
                "tokenized_tecla = tokenized_tecla.map(convert_label_to_int, batched=True, desc=\"Processing labels..\")\n",
                "\n",
                "# Display the processed tokenized_tecla dataset.\n",
                "tokenized_tecla"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Finally, we will use the `label_1` column from the dataset and rename it to the standard column name `label`. Standardizing the label name is crucial because most Hugging Face models are designed to look specifically for a column named `label` when fine-tuning for classification tasks. Using a different name could lead to errors or the model failing to recognize the labels correctly during training.\n",
                "\n",
                "Renaming the column ensures the model can automatically identify the labels without requiring additional configuration adjustments.\n",
                "\n",
                "**Important**:  \n",
                "The model only requires the following columns for fine-tuning:  \n",
                "- **`input_ids`**: The list of token indices generated by the tokenizer.  \n",
                "- **`attention_mask`**: A list indicating which tokens should be attended to (1 for real tokens, 0 for padding).  \n",
                "- **`label`**: The numerical representation of the class label for each example.  \n",
                "\n",
                "All other columns in the dataset will be ignored during the fine-tuning process. Therefore, it\u2019s recommended to remove any unnecessary columns after preprocessing to avoid confusion and reduce memory usage during training."
            ],
            "metadata": {
                "id": "OtBbSVjnbPPJ"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Iterate over each split (e.g., 'train', 'test', 'validation') in the tokenized_tecla dataset.\n",
                "for split in tokenized_tecla.keys():\n",
                "  # Rename the 'label1' column to 'label' for consistency in each split.\n",
                "  tokenized_tecla[split] = tokenized_tecla[split].rename_column(\"label1\", \"label\")\n",
                "  # Remove the original 'sentence' and 'label2' columns as they are no longer needed.\n",
                "  tokenized_tecla[split]  = tokenized_tecla[split].remove_columns(\n",
                "    [\"sentence\", \"label2\"]\n",
                ")\n",
                "\n",
                "# Display the updated tokenized_tecla dataset.\n",
                "tokenized_tecla"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Evaluation\n",
                "\n",
                "Before starting the training process, it is important to include a metric that will help us evaluate the performance of the model throughout the training. Having an evaluation metric allows us to track the model\u2019s progress and make sure it is learning effectively.\n",
                "\n",
                "To quickly integrate an evaluation method, we can use the `evaluate` library. This library provides a simple way to load and use a variety of evaluation metrics. For this specific task, we will load the **accuracy** metric from the `evaluate` library, which is commonly used to measure how often the model's predictions match the true labels.\n",
                "\n",
                "Using accuracy as the evaluation metric, we can monitor how well the model performs on the validation or test set after each training epoch. This allows us to make adjustments or stop training if the model starts to overfit or if its performance plateaus.\n"
            ],
            "metadata": {
                "id": "kCKqB0SkzjVB"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the 'evaluate' library, which provides tools for evaluating machine learning models.\n",
                "import evaluate\n",
                "\n",
                "# Load the 'accuracy' metric from the 'evaluate' library.\n",
                "# This metric will be used to calculate the accuracy of the model's predictions.\n",
                "accuracy = evaluate.load(\"accuracy\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Next, create a function called `compute_metrics` that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) and returns the accuracy score.\n"
            ],
            "metadata": {
                "id": "2p0fEe1g0YEk"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the NumPy library for numerical operations, particularly for working with arrays.\n",
                "import numpy as np\n",
                "\n",
                "def compute_accuracy(eval_pred):\n",
                "  \"\"\"\n",
                "  Computes the accuracy of the model's predictions.\n",
                "\n",
                "  Args:\n",
                "    eval_pred: A tuple containing the model's predictions and the true labels.\n",
                "\n",
                "  Returns:\n",
                "    A dictionary containing the accuracy score.\n",
                "  \"\"\"\n",
                "  # Extract predictions and labels from eval_pred.\n",
                "  predictions, labels = eval_pred\n",
                "  # Get the predicted class by finding the index of the highest probability for each prediction.\n",
                "  predictions = np.argmax(predictions, axis=1)\n",
                "  # Compute and return the accuracy using the accuracy metric.\n",
                "  return accuracy.compute(predictions=predictions, references=labels)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Training\n",
                "\n",
                "Now, we will fine-tune our model for the text classification task by adding a classification layer on top of the pre-trained model. Fine-tuning allows the model to adapt to the specific task and learn to classify text based on the provided labels.\n",
                "\n",
                "To do this, we create a classification layer using the [`AutoModelForSequenceClassification`](https://huggingface.co/docs/transformers/model_doc/auto) class from the Hugging Face `transformers` library. This class is designed for sequence classification tasks and can be easily adapted to work with pre-trained models.\n",
                "\n",
                "When creating the model, we define the number of labels (classes) and provide the label-to-ID mapping. This enables the model to learn how to map the predicted outputs to the appropriate class labels during training and inference.\n",
                "\n",
                "By using this approach, we leverage the power of a pre-trained model while adapting it to our specific classification problem.\n"
            ],
            "metadata": {
                "id": "QPTprBWr1jfo"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the AutoModelForSequenceClassification class from the transformers library.\n",
                "# This class is used to load a pre-trained model for sequence classification.\n",
                "from transformers import AutoModelForSequenceClassification\n",
                "\n",
                "# Load the pre-trained model \"projecte-aina/roberta-base-ca-v2\" for sequence classification.\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\"projecte-aina/roberta-base-ca-v2\",\n",
                "                                                           num_labels=len(labels), # num_labels specifies the number of output labels for the classification task.\n",
                "                                                           label2id=label2id, # # label2id and id2label dictionaries map between labels and their corresponding IDs.\n",
                "                                                           id2label=id2label)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Check the model configuration and get familiar with all the fields, such as label-related, model-related and similar."
            ],
            "metadata": {
                "id": "d4M6P1ctRIJI"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "model.config"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "We define the hyperparameters using [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). This step is crucial for setting up the training strategy and configuration.\n",
                "\n",
                "In this configuration, we specify that the model will be trained for 1000 steps. Additionally, the model will be evaluated on the validation dataset every 100 steps to monitor its performance during training. We also configure the saving of checkpoints at regular intervals to allow us to resume training if needed and keep track of the model's progress over time.\n",
                "\n",
                "By defining these hyperparameters, we control the training process, including how often to evaluate, how many steps to train, and how to save checkpoints, ensuring an efficient and organized training workflow.\n"
            ],
            "metadata": {
                "id": "SfqIwniz9MhA"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the TrainingArguments class from the transformers library.\n",
                "# This class is used to define the hyperparameters for training a transformer model.\n",
                "from transformers import TrainingArguments\n",
                "\n",
                "# Define the training arguments for the model.\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"tecla_model\", # Directory to save the trained model.\n",
                "    evaluation_strategy=\"steps\", # Evaluate the model at specified intervals (steps).\n",
                "    save_strategy=\"steps\", # Save the model at specified intervals (steps).\n",
                "    save_steps=100, # Save the model every 100 steps.\n",
                "    eval_steps=100, # Evaluate the model every 100 steps.\n",
                "    max_steps=1000, # Total number of training steps.\n",
                "    logging_steps=10,  # Log training information every 10 steps.\n",
                "    num_train_epochs=1, # Number of training epochs (one full pass over the training data).\n",
                "    learning_rate=2e-5, # Learning rate for the optimizer.\n",
                "    per_device_train_batch_size=10, # Batch size for training on each device.\n",
                "    per_device_eval_batch_size=10, # Batch size for evaluation on each device.\n",
                "    logging_dir='tecla_model/logs', # Directory to save training logs.\n",
                "    report_to=\"tensorboard\") # Enable Tensorboard reporting"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Inspect all the training arguments, including defualt ones, and get familiar with them. You will see a lot of them. They are fundamental to control the training loop."
            ],
            "metadata": {
                "id": "qSpIP6WsTnwd"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "training_args"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now, pass the training arguments to the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, and the `compute_metrics` function. The `Trainer` class simplifies the training process by managing most of the training loop internally.\n",
                "\n",
                "The following arguments are passed to the `Trainer`:\n",
                "\n",
                "- **`model`**:\n",
                "  - The pre-trained model that will be fine-tuned. This model (e.g., `projecte-aina/roberta-base-ca-v2`) will be used for the sequence classification task.\n",
                "\n",
                "- **`args`**:\n",
                "  - The training arguments, which are defined using the `TrainingArguments` class. These arguments determine how the training proceeds, such as how often the model should be evaluated, the save strategy, the batch size, the learning rate, and more.\n",
                "\n",
                "- **`train_dataset`**:\n",
                "  - The dataset used for training. This is typically the processed training data (e.g., `dataset['train']`) that the model will learn from.\n",
                "\n",
                "- **`eval_dataset`**:\n",
                "  - The validation dataset, used to evaluate the model at intervals during the training process. It allows us to track the model's performance and prevent overfitting.\n",
                "\n",
                "- **`tokenizer`**:\n",
                "  - The tokenizer used to preprocess text data. It converts raw text into tokens that the model can understand. The tokenizer ensures that text is processed in the same way it was when the model was pre-trained.\n",
                "\n",
                "- **`compute_metrics`**:\n",
                "  - A function that computes the evaluation metrics, such as accuracy. This function will be used by the `Trainer` during validation to calculate the model\u2019s performance based on the predictions and the true labels.\n",
                "\n",
                "Once all these arguments are passed to the `Trainer`, you can call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to start fine-tuning the model. This method will begin the training process using the defined settings, iterating over the dataset and updating the model weights based on the defined optimization and evaluation strategy.\n",
                "\n"
            ],
            "metadata": {
                "id": "qcoCgdyw-6nk"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Prevent potential CUDA error.\n",
                "!export CUDA_LAUNCH_BLOCKING=1"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the Trainer class from the transformers library.\n",
                "from transformers import Trainer\n",
                "\n",
                "trainer = Trainer(\n",
                "# TODO: Initialize the Trainer with the specified arguments.\n",
                "    model=\n",
                "    args=\n",
                "    train_dataset=\n",
                "    eval_dataset=\n",
                "    tokenizer=\n",
                "    compute_metrics=\n"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Finally, start the training and monitor it with the tensorboard!"
            ],
            "metadata": {
                "id": "UmKaMGASUto_"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Load the TensorBoard extension for visualizing training progress.\n",
                "%load_ext tensorboard\n",
                "\n",
                "# Start TensorBoard and point it to the log directory.\n",
                "# Replace './logs' with the actual path to your log directory.\n",
                "%tensorboard --logdir ./logs\n",
                "\n",
                "# Begin training the model using the Trainer instance.\n",
                "# This will also log data to TensorBoard for visualization.\n",
                "trainer.train()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Inference\n",
                "\n",
                "Now, let's perform inference using the [pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) abstraction on the same zero-shot example from TeCla, utilizing the fine-tuned models.\n",
                "\n",
                "The `pipeline` API simplifies the process of making predictions with pre-trained models. It handles the input data, model inference, and outputs the results in an easy-to-understand format. For text classification, we can use the pipeline to predict the class of a given text, even without explicitly writing the model inference code.\n",
                "\n",
                "When performing inference in a zero-shot setting (without retraining the model on specific classes), we can pass text directly to the pipeline, and it will return predictions. This allows us to apply the fine-tuned model to new, unseen examples and classify them accordingly.\n",
                "\n",
                "Unlike the previous inference in zero-shot setting, in this case, we will use the model we just trained (fine-tuned on TeCla) and apply it to a new sample, utilizing the pipeline abstraction to make predictions efficiently.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ],
            "metadata": {
                "id": "GgeDjEzGDks9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the pipeline function for easy model inference.\n",
                "from transformers import pipeline\n",
                "\n",
                "# Specify the path to the fine-tuned model checkpoint.\n",
                "model_finetuned = \"/content/tecla_model/checkpoint-100\"\n",
                "\n",
                "# Create a text classification pipeline using the fine-tuned model.\n",
                "# device=0 indicates using the first available GPU.\n",
                "classifier = pipeline(\"text-classification\", model=model_finetuned, device=0)\n",
                "\n",
                "# Get a test sentence and its true label from the 'tecla' dataset.\n",
                "# Assuming 'tecla' is a dictionary containing the test data.\n",
                "text = tecla[\"test\"][0][\"sentence\"]\n",
                "label = tecla[\"test\"][0][\"label1\"]\n",
                "\n",
                "# Perform prediction on the first 1000 characters of the sentence. This is necessary because sentences could exceed the maximum model length\n",
                "prediction = classifier(text[:1000])[0]['label']\n",
                "\n",
                "# Print the original sentence, predicted label, and true label.\n",
                "print(\"Sentence:\", text)\n",
                "print(\"Predicted Label:\", prediction)\n",
                "print(\"Label:\", label)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Exercise 1\n",
                "\n",
                "## Objective:\n",
                "\n",
                "Create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). This approach dynamically pads the sentences to the longest sequence in a given batch during collation, which is more efficient than padding the entire dataset to a fixed maximum length. By doing this, you avoid excessive padding, reduce memory usage, and speed up the training process, as each batch only gets padded to the necessary length.\n",
                "\n",
                "\n",
                "## Suggestion:\n",
                "The `data_collator` is passed as an argument to the `Trainer`.\n"
            ],
            "metadata": {
                "id": "h_ZlJ910h4r9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the Trainer class from the transformers library.\n",
                "from transformers import Trainer\n",
                "\n",
                "# TODO: import the data collator with padding\n",
                "\n",
                "# Create a data collator for padding sequences in a batch.\n",
                "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
                "\n",
                "# Initialize the Trainer using data_collator and all the other arguments\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_tecla[\"train\"],\n",
                "    eval_dataset=tokenized_tecla[\"validation\"],\n",
                "    tokenizer=tokenizer,\n",
                "    compute_metrics=compute_accuracy,\n",
                "# TODO: Initialize the Trainer using data_collator\n",
                "    data_collator=\n",
                "\n",
                ")\n",
                "\n",
                "# Load the TensorBoard extension for visualizing training progress.\n",
                "%load_ext tensorboard\n",
                "\n",
                "# Start TensorBoard and point it to the log directory.\n",
                "# Replace './logs' with the actual path to your log directory.\n",
                "%tensorboard --logdir ./logs\n",
                "\n",
                "# Begin training the model using the Trainer instance.\n",
                "# This will also log data to TensorBoard for visualization.\n",
                "trainer.train()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Exercise 2\n",
                "\n",
                "## Objective:\n",
                "Implement the F1 score as the validation metric instead of accuracy during training.\n",
                "\n",
                "## Suggestion:\n",
                "Use the `compute_accuracy` function as a reference."
            ],
            "metadata": {
                "id": "NwzBNbmi2F3k"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the 'evaluate' library, which provides tools for evaluating machine learning models.\n",
                "import evaluate\n",
                "# Import the NumPy library for numerical operations, particularly for working with arrays.\n",
                "import numpy as np\n",
                "\n",
                "# TODO: Load the 'f1' metric from the 'evaluate' library.\n",
                "# This metric will be used to calculate the accuracy of the model's predictions.\n",
                "\n",
                "# TODO: Implement the F1 metric\n",
                "  # Extract predictions and labels from eval_pred.\n",
                "  # Get the predicted class by finding the index of the highest probability for each prediction.\n",
                "  # Compute and return the accuracy using the accuracy metric.\n"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now, start the training with the F1 metric as evaluation."
            ],
            "metadata": {
                "id": "n1rX1Qx7JVRQ"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Import the Trainer class from the transformers library.\n",
                "from transformers import Trainer\n",
                "\n",
                "# Initialize the Trainer using data_collator and all the other arguments\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_tecla[\"train\"].select(range(10)),\n",
                "    eval_dataset=tokenized_tecla[\"validation\"].select(range(10)),\n",
                "    tokenizer=tokenizer,\n",
                "    compute_metrics=compute_f1,\n",
                ")\n",
                "\n",
                "# Load the TensorBoard extension for visualizing training progress.\n",
                "%load_ext tensorboard\n",
                "\n",
                "# Start TensorBoard and point it to the log directory.\n",
                "# Replace './logs' with the actual path to your log directory.\n",
                "%tensorboard --logdir ./logs\n",
                "\n",
                "# Begin training the model using the Trainer instance.\n",
                "# This will also log data to TensorBoard for visualization.\n",
                "trainer.train()\n"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}
