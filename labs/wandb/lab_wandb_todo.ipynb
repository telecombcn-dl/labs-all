{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "60013bc2",
            "metadata": {
                "id": "60013bc2"
            },
            "source": [
                "# Experiment Tracking with Weights & Biases (W&B)\n",
                "*Created by **Laia Albors**, **Jorge Pueyo** and **\u00c0lex Sol\u00e9** (2025)*\n",
                "\n",
                "This lab introduces you to [**Weights & Biases (W&B)**](https://docs.wandb.ai/), a powerful tool for tracking machine learning experiments. You will learn how to set up projects, log data such as metrics, images, and configurations, and explore results through the W&B interface. By the end, you will be able to organize experiments effectively and gain valuable insights into your models.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "oTw5Et_0AT3e",
            "metadata": {
                "id": "oTw5Et_0AT3e"
            },
            "source": [
                "## PART 1: Getting Started"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85b7443d",
            "metadata": {
                "id": "85b7443d"
            },
            "source": [
                "### 0) Setup\n",
                "First we need to install W&B:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "559a52ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q wandb"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4a49dbc2",
            "metadata": {
                "id": "4a49dbc2"
            },
            "source": [
                "### 1) Create an account and log in\n",
                "\n",
                "Once installed, we need an account and an API key:\n",
                "\n",
                "1. Go to [**wandb.ai**](https://app.wandb.ai/login?signup=true) and create an account (you can sign in with GitHub/Google).\n",
                "2. Now, you can log in from Python using `wandb.login()`.\n",
                "3. Use the interactive prompt or environment variables to set your API key.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1594a38c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "import wandb\n",
                "\n",
                "# The call below will open a prompt in the notebook/terminal to paste your API key (once).\n",
                "# Alternatively, you can set the env var WANDB_API_KEY before running this cell.\n",
                "wandb.login()  # <- follow the instructions in the output\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cce69042",
            "metadata": {
                "id": "cce69042"
            },
            "source": [
                "### 2) Configure a project & initialize a run\n",
                "\n",
                "In W&B, **each experiment is a _run_**, and runs are **grouped into _projects_**. In this first part, we\u2019ll just create a small example project (`aa2-wandb-lab`) and a few demo runs to understand the workflow. Later, you\u2019ll reuse the same project while training a real network.\n",
                "\n",
                "We\u2019ll also attach some **config** (hyperparameters/metadata), **tags** (to filter/search), and **notes** (short description)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1a588e3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "PROJECT = \"aa2-wandb-lab\"            # keep it short & consistent across the course\n",
                "RUN_NAME = \"intro-logging\"           # optional but useful\n",
                "TAGS = [\"intro\", \"logging\", \"part1\"] # you can add/remove as you like\n",
                "NOTES = \"First steps with W&B: login, init, log scalars/images/matrices.\"\n",
                "\n",
                "# Anything you place under config will be versioned & shown in the UI.\n",
                "config = dict(\n",
                "    seed=42,\n",
                "    batch_size=32,\n",
                "    lr=1e-3,\n",
                "    comment=\"config is just metadata for this run\"\n",
                ")\n",
                "\n",
                "# Initialize a run. If you're inside a Jupyter notebook,\n",
                "# W&B will automatically attach the notebook as an artifact (unless disabled).\n",
                "init_kwargs = dict(\n",
                "    project=PROJECT,\n",
                "    name=RUN_NAME,\n",
                "    tags=TAGS,\n",
                "    notes=NOTES,\n",
                "    config=config\n",
                ")\n",
                "\n",
                "run = wandb.init(**init_kwargs)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "K7Cn9GN_3Z4O",
            "metadata": {
                "id": "K7Cn9GN_3Z4O"
            },
            "source": [
                "If you click the link shown after **\u201cView project at\u201d**, you\u2019ll be taken to the W&B project page (`aa2-wandb-lab`).  At this point, you should see only a single run listed there, named **`intro-logging`**.\n",
                "\n",
                "From the project page, you can either click on this run or use the link printed after **\u201cView run at\u201d**.  This will open the detailed dashboard for that specific run, where all metrics and artifacts are tracked.  Right now, you\u2019ll only see **system-level metrics** (CPU/GPU usage, memory, etc.), since we haven\u2019t logged any custom values yet.\n",
                "\n",
                "If you return to the project page showing all runs, notice that you are in the **\"Workspace\"** view by default.  If you switch to the **\"Runs\"** tab on the left, W&B will display a table of all runs in the project.  Here you can easily inspect the **init arguments** we defined earlier\u2014such as tags, notes, and configuration values (`seed`, `batch_size`, `lr`, etc.)\u2014for each run. This view is especially useful when you start comparing multiple experiments side by side.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aae06cc7",
            "metadata": {
                "id": "aae06cc7"
            },
            "source": [
                "### 3) Log numbers (scalars)\n",
                "\n",
                "Now that our run is initialized, let\u2019s start recording some metrics into it.  \n",
                "The main way to do this is with **`wandb.log({...})`**, which sends a dictionary of key\u2013value pairs to W&B.  \n",
                "\n",
                "In practice, these calls usually happen inside your training and validation loops (e.g., logging loss and accuracy after each step or epoch).  \n",
                "Here we\u2019ll simulate this by logging a few dummy values (`train/loss`, `val/loss`, and `val/accuracy`) across 10 steps, so you can immediately see them appear in the run dashboard you opened earlier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5cc3afc4",
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import random\n",
                "import time\n",
                "\n",
                "# Simulate logging of a few scalar metrics across steps\n",
                "for step in range(1, 11):\n",
                "    train_loss = math.exp(-step/5.0) + random.random() * 0.02\n",
                "    val_loss = train_loss + 0.05 + random.random() * 0.02\n",
                "    acc = 1.0 - val_loss\n",
                "\n",
                "    wandb.log({\n",
                "        \"step\": step,\n",
                "        \"train/loss\": train_loss,\n",
                "        \"val/loss\": val_loss,\n",
                "        \"val/accuracy\": acc\n",
                "    })\n",
                "    time.sleep(0.1)  # just to make the timeline nicer\n",
                "\n",
                "print(\"Logged scalar metrics for 10 steps.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "RFBsBB5w9_D_",
            "metadata": {
                "id": "RFBsBB5w9_D_"
            },
            "source": [
                "In the W&B run page, you should now see three new sections:\n",
                "\n",
                "- **Charts**, which contains the default `steps` plot.  \n",
                "- **train**, with a plot showing the `train/loss` values we logged for each step.  \n",
                "- **val**, with two plots: one for `val/loss` and another for `val/accuracy`.  \n",
                "\n",
                "Each point in these plots comes from a call to `wandb.log`, and the x-axis corresponds to the `step` we logged."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ed84ac5e",
            "metadata": {
                "id": "ed84ac5e"
            },
            "source": [
                "### 4) Log images\n",
                "\n",
                "So far we\u2019ve only logged numeric values, but W&B can also handle richer data types.  \n",
                "A common use case during training is to **visualize model predictions as images** (e.g., inputs, reconstructions, or segmentations).  \n",
                "\n",
                "To log an image, simply wrap it with `wandb.Image`. This works with arrays (NumPy/PyTorch) or with `PIL.Image` objects.  \n",
                "You can also add a **caption** to give context to what\u2019s being shown.  \n",
                "\n",
                "Below we create a small synthetic image (a color gradient with a white rectangle) just to see how images are logged.  \n",
                "In the W&B run page, you\u2019ll find the result in a new **demo** section, under the key `demo/image`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "294997b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from PIL import Image, ImageDraw\n",
                "\n",
                "# Create a simple synthetic image (RGB gradient with a rectangle) just for demo\n",
                "H, W = 128, 128\n",
                "gradient = np.zeros((H, W, 3), dtype=np.uint8)\n",
                "for y in range(H):\n",
                "    for x in range(W):\n",
                "        gradient[y, x, :] = [x * 255 // (W-1), y * 255 // (H-1), 128]\n",
                "\n",
                "img = Image.fromarray(gradient)\n",
                "draw = ImageDraw.Draw(img)\n",
                "draw.rectangle([32, 32, 96, 96], outline=(255, 255, 255), width=3)\n",
                "\n",
                "wandb.log({\n",
                "    \"step\": 11,\n",
                "    \"demo/image\": wandb.Image(img, caption=\"Synthetic demo image\")\n",
                "})\n",
                "\n",
                "print(\"Logged one demo image.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2fb0c63a",
            "metadata": {
                "id": "2fb0c63a"
            },
            "source": [
                "### 5) Log matrices\n",
                "\n",
                "Besides numbers and images, W&B can also log **matrices**, which are very common in ML workflows.  \n",
                "There are several ways to represent them, depending on what you want to highlight:\n",
                "\n",
                "- **As a heatmap image**: render with matplotlib and wrap in `wandb.Image`.  \n",
                "- **As a histogram**: summarize the distribution of values with `wandb.Histogram(matrix)`.  \n",
                "- **As a table**: store the raw values in a `wandb.Table`, useful for small matrices you want to inspect cell by cell.  \n",
                "- **As a confusion matrix**: use `wandb.plot.confusion_matrix` when working on classification tasks to compare predictions against ground truth.\n",
                "\n",
                "Below we show all of these options:\n",
                "\n",
                "1. A random 32\u00d732 matrix logged as a heatmap, a histogram, and a small table.  \n",
                "2. A **synthetic confusion matrix example**, where we pretend we have ground-truth labels and model predictions for a 2-class problem. This is exactly the kind of plot you\u2019ll use later with your CNN.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "795849a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Create a random matrix\n",
                "M = np.random.randn(32, 32)\n",
                "\n",
                "# 1) Heatmap as image\n",
                "plt.figure()\n",
                "plt.imshow(M)\n",
                "plt.title(\"Random matrix heatmap\")\n",
                "plt.colorbar()\n",
                "plt.tight_layout()\n",
                "wandb.log({\n",
                "    \"step\": 12,\n",
                "    \"demo/matrix_heatmap\": wandb.Image(plt)\n",
                "})\n",
                "plt.close()\n",
                "\n",
                "# 2) Histogram of values\n",
                "wandb.log({\n",
                "    \"step\": 13,\n",
                "    \"demo/matrix_hist\": wandb.Histogram(M)\n",
                "})\n",
                "\n",
                "# 3) Small table (be careful with large arrays!)\n",
                "small = M[:5, :5]\n",
                "table = wandb.Table(data=small.tolist(), columns=[f\"c{i}\" for i in range(small.shape[1])])\n",
                "wandb.log({\n",
                "    \"step\": 14,\n",
                "    \"demo/matrix_table\": table\n",
                "})\n",
                "\n",
                "# 4) Example confusion matrix (binary case)\n",
                "true_labels = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1]\n",
                "pred_labels = [0, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n",
                "\n",
                "wandb.log({\n",
                "    \"step\": 15,\n",
                "    \"demo/conf_matrix\": wandb.plot.confusion_matrix(\n",
                "        probs=None,\n",
                "        y_true=true_labels,\n",
                "        preds=pred_labels,\n",
                "        class_names=[\"negative\", \"positive\"]\n",
                "    )\n",
                "})\n",
                "\n",
                "print(\"Logged matrix as heatmap, histogram, table, and confusion matrix.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "Teizh4qJGTWL",
            "metadata": {
                "id": "Teizh4qJGTWL"
            },
            "source": [
                "If you refresh the W&B run page, you should now see several new panels in the **demo** section:\n",
                "\n",
                "- **Confusion Matrix Curve** \u2192 visualization of predictions vs. ground truth.  \n",
                "  - Rows = actual labels, columns = predicted labels.  \n",
                "  - Each cell shows how many examples fell into that category (e.g. true positives, false negatives).\n",
                "\n",
                "- **demo/matrix_heatmap** \u2192 a heatmap of the random 32\u00d732 matrix we logged with matplotlib.  \n",
                "  - Bright vs. dark areas correspond to higher vs. lower values.  \n",
                "  - This is similar to how you might visualize filters or attention maps.\n",
                "\n",
                "- **demo/matrix_hist** \u2192 a histogram of the matrix values.  \n",
                "  - Y-axis = bins of values (from negative to positive).  \n",
                "  - Color intensity = how many values fell into each bin.  \n",
                "  - This is useful to check the distribution of weights, activations, or gradients during training.\n",
                "\n",
                "- **demo/matrix_table** \u2192 a table view of a 5\u00d75 slice of the matrix with the raw numbers.  \n",
                "  - Helpful when you want to inspect specific values rather than just the visualization.\n",
                "\n",
                "- **demo/conf_matrix_table** \u2192 the backing data for the confusion matrix plot.  \n",
                "  - For each (Actual, Predicted) pair, it shows how many samples were counted.\n",
                "\n",
                "Together, these examples show the different ways W&B can log and visualize matrices: as plots, distributions, tables of numbers, or task-specific charts like confusion matrices."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "859462c6",
            "metadata": {
                "id": "859462c6"
            },
            "source": [
                "### 6) Attach files and artifacts\n",
                "\n",
                "So far, we\u2019ve logged **metrics** (scalars), **images**, and **matrices** directly into W&B.  \n",
                "Another powerful feature is the ability to attach **files** to a run, so they are versioned and stored alongside your metrics.  \n",
                "\n",
                "This is especially useful when you want to keep track of external resources such as:  \n",
                "- Training logs or notes saved to a `.txt` file.  \n",
                "- Example predictions saved to disk.  \n",
                "- **Model checkpoints** (in Part 3 of this notebook, we\u2019ll see how to upload and version them properly as *artifacts*).  \n",
                "\n",
                "In this simple example, we\u2019ll create a tiny text file and upload it with `wandb.save`.  \n",
                "Once logged, the file will appear in the run page under the **Files** tab, so you can always recover it later.  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c31ab5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write a small text file and save it as an \"artifact\" via log\n",
                "with open(\"hello_wandb.txt\", \"w\") as f:\n",
                "    f.write(\"Hello W&B from AA2!\\n\")\n",
                "\n",
                "wandb.save(\"hello_wandb.txt\")  # uploads & versions this file for the run\n",
                "\n",
                "print(\"Attached a small text file to the run.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "545b1a6b",
            "metadata": {
                "id": "545b1a6b"
            },
            "source": [
                "### 7) Wrapping up Part 1\n",
                "\n",
                "In this first part, you\u2019ve learned how to set up W&B, create a project and runs, and log different types of data: **scalars, images, matrices, and files**.  This already gives you a complete toolkit to track experiments, but so far we\u2019ve only worked with toy examples.  \n",
                "\n",
                "In **Parts 2** and **3**, you\u2019ll put this into practice by training a real **CNN** and using W&B to log training and validation metrics, visualize predictions, build confusion matrices, and even save checkpoints as artifacts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4aea2159",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Always finish your run to ensure everything is uploaded\n",
                "wandb.finish()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bbb08a68",
            "metadata": {
                "id": "bbb08a68"
            },
            "source": [
                "## PART 2: Logging your Experiment\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "MvDOUOp3JO2I",
            "metadata": {
                "id": "MvDOUOp3JO2I"
            },
            "source": [
                "### 8) Initialize a new experiment\n",
                "We will start by creating a new run and defining the hyperparameters that will be used for this experiment.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "UlCDB0gKKNZh",
            "metadata": {},
            "outputs": [],
            "source": [
                "PROJECT = \"aa2-wandb-lab\"\n",
                "RUN_NAME = \"cnn_mnist\"\n",
                "hparams = {\n",
                "    'kernel_size': 5,\n",
                "    'num_inp_channels': 1,\n",
                "    'num_out_fmaps_1': 6,\n",
                "    \"num_out_fmaps_2\": 16,\n",
                "    'num_classes':10,\n",
                "\n",
                "    'batch_size':64,\n",
                "    'num_epochs':5,\n",
                "    'test_batch_size':64,\n",
                "    'learning_rate': 1e-3,\n",
                "    'log_interval':100,\n",
                "}\n",
                "\n",
                "init_kwargs = dict(\n",
                "    project=PROJECT,\n",
                "    name=RUN_NAME,\n",
                "    config=hparams\n",
                ")\n",
                "run = wandb.init(**init_kwargs)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "NVuZevNpOsts",
            "metadata": {
                "id": "NVuZevNpOsts"
            },
            "source": [
                "### 9) Defining our Network\n",
                "In this exercise we will define the same `PseudoLeNet` network used in the previous lab. However, this time we will define it so it accepts a `dict` containing the value of the parameters of the network, so we can define the model in a dynamic way.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "o_C97zpzJOBp",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from typing import Tuple, Dict, Any, List\n",
                "\n",
                "class ConvBlock(nn.Module):\n",
                "\n",
                "    def __init__(\n",
                "            self,\n",
                "            num_inp_channels: int,\n",
                "            num_out_fmaps: int,\n",
                "            kernel_size: int,\n",
                "            pool_size: int=2) -> None:\n",
                "\n",
                "        super().__init__()\n",
                "\n",
                "        self.conv = nn.Conv2d(\n",
                "            in_channels=num_inp_channels,\n",
                "            out_channels=num_out_fmaps,\n",
                "            kernel_size=(kernel_size, kernel_size))\n",
                "        self.relu = nn.ReLU(inplace=True)\n",
                "        self.maxpool = nn.MaxPool2d(kernel_size=(pool_size, pool_size))\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        return self.maxpool(self.relu(self.conv(x)))\n",
                "\n",
                "\n",
                "class PseudoLeNet(nn.Module):\n",
                "\n",
                "  def __init__(self, hparams: dict) -> None:\n",
                "      super().__init__()\n",
                "      # TODO: Define the zero-padding\n",
                "      self.pad = ...\n",
                "\n",
                "      # TODO: Define the convolutional layers according to the hyperparameters\n",
                "      self.conv1 = ...\n",
                "      self.conv2 = ...\n",
                "\n",
                "      self.mlp = nn.Sequential(\n",
                "          nn.Linear(in_features=hparams[\"num_out_fmaps_2\"] * hparams[\"kernel_size\"] * hparams[\"kernel_size\"], out_features=120),\n",
                "          nn.ReLU(inplace=True),\n",
                "          nn.Linear(in_features=120, out_features=84),\n",
                "          nn.ReLU(inplace=True),\n",
                "          nn.Linear(in_features=84, out_features=hparams[\"num_classes\"]),\n",
                "          nn.LogSoftmax(dim=-1)\n",
                "      )\n",
                "\n",
                "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "      x = self.pad(x)\n",
                "      x = self.conv1(x)\n",
                "      x = self.conv2(x)\n",
                "\n",
                "      bsz, nch, height, width = x.shape\n",
                "\n",
                "      # TODO: Flatten the feature map with the reshape() operator\n",
                "      # within each batch sample\n",
                "      x = ...\n",
                "\n",
                "      y = self.mlp(x)\n",
                "      return y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "Fu13Xs90A3l4",
            "metadata": {},
            "outputs": [],
            "source": [
                "x = torch.randn(1, 1, 28, 28)\n",
                "network = PseudoLeNet(hparams)\n",
                "y = network(x)\n",
                "print(f\"Output shape: {y.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2tuh8XBIRttL",
            "metadata": {
                "id": "2tuh8XBIRttL"
            },
            "source": [
                "### 10) Logging Training and Testing\n",
                "In this part, we will train our network and learn how to log the training and testing loops to W&B for more convenient monitoring.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "Y72fExokTNNd",
            "metadata": {
                "id": "Y72fExokTNNd"
            },
            "source": [
                "Start by creating the MNIST train/test dataloaders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "KT69yaG9RuDC",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision import datasets, transforms\n",
                "\n",
                "transforms = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "\n",
                "# Dataset initializations\n",
                "\n",
                "mnist_trainset = datasets.MNIST(\n",
                "  root='data',\n",
                "  train=True,\n",
                "  download=True,\n",
                "  transform=transforms\n",
                ")\n",
                "\n",
                "# deterministically sample 1k train examples for demo purposes\n",
                "seed = int(hparams.get(\"seed\", 42))\n",
                "g = torch.Generator()\n",
                "g.manual_seed(seed)\n",
                "num_samples = 1000\n",
                "total = len(mnist_trainset)\n",
                "selected_indices = torch.randperm(total, generator=g)[:num_samples].tolist()\n",
                "subset_train = torch.utils.data.Subset(mnist_trainset, selected_indices)\n",
                "\n",
                "mnist_testset = datasets.MNIST(\n",
                "  root='data',\n",
                "  train=False,\n",
                "  download=True,\n",
                "  transform=transforms\n",
                ")\n",
                "\n",
                "# Dataloders initialization\n",
                "\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "  dataset=subset_train,\n",
                "  batch_size=hparams['batch_size'],\n",
                "  shuffle=True,\n",
                "  drop_last=True,\n",
                ")\n",
                "\n",
                "test_loader = torch.utils.data.DataLoader(\n",
                "  dataset=mnist_testset,\n",
                "  batch_size=hparams['test_batch_size'],\n",
                "  shuffle=False,\n",
                "  drop_last=False, # Changed from True to False\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "E3Qn1xzhTDJ9",
            "metadata": {
                "id": "E3Qn1xzhTDJ9"
            },
            "source": [
                "Create the loss function to evaluate the performance of your model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "tO2FdKgGSqCW",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_accuracy(predicted_batch: torch.Tensor, label_batch: torch.Tensor) -> int:\n",
                "    \"\"\"\n",
                "    Define the Accuracy metric in the function below by:\n",
                "      (1) obtain the maximum for each predicted element in the batch to get the\n",
                "        class (it is the maximum index of the num_classes array per batch sample)\n",
                "        (look at torch.argmax in the PyTorch documentation)\n",
                "      (2) compare the predicted class index with the index in its corresponding\n",
                "        neighbor within label_batch\n",
                "      (3) sum up the number of affirmative comparisons and return the summation\n",
                "\n",
                "    Parameters:\n",
                "    -----------\n",
                "    predicted_batch: torch.Tensor shape: [BATCH_SIZE, N_CLASSES]\n",
                "        Batch of predictions\n",
                "    label_batch: torch.Tensor shape: [BATCH_SIZE, 1]\n",
                "        Batch of labels / ground truths.\n",
                "    \"\"\"\n",
                "    pred = predicted_batch.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
                "    acum = pred.eq(label_batch.view_as(pred)).sum().item()\n",
                "    return acum"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "AjwVnqp4UWmj",
            "metadata": {
                "id": "AjwVnqp4UWmj"
            },
            "source": [
                "Complete the function to train the network for one epoch. Remember the five key steps:\n",
                "\n",
                "\n",
                "1.   Set all parameters' gradients to **zero**.\n",
                "2.   Perform the **forward** pass.\n",
                "3.   Compute the **loss** function.\n",
                "4.   Perform the **backward** pass.\n",
                "4.   **Update** the network's parameters.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5EjhJwRSJiJ",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "def train_epoch(\n",
                "    train_loader: torch.utils.data.DataLoader,\n",
                "    network: torch.nn.Module,\n",
                "    optimizer: torch.optim,\n",
                "    criterion: torch.nn.functional,\n",
                "    log_interval: int,\n",
                "  ) -> Tuple[float, float]:\n",
                "\n",
                "  # Activate the train=True flag inside the model\n",
                "  network.train()\n",
                "\n",
                "  train_loss = []\n",
                "  acc = 0.\n",
                "  avg_weight = 0.1\n",
                "  for batch_idx, (data, target) in enumerate(train_loader):\n",
                "\n",
                "      #TODO: Move input data and labels to the device\n",
                "      data, target = ...\n",
                "\n",
                "      #TODO: Set network gradients to 0.\n",
                "      optimizer. ...\n",
                "\n",
                "      #TODO: Forward batch of images through the network\n",
                "      output = ...\n",
                "\n",
                "      #TODO: Compute loss\n",
                "      loss = ...\n",
                "\n",
                "      #TODO: Compute backpropagation\n",
                "      loss. ...\n",
                "\n",
                "      #TODO: Update parameters of the network\n",
                "      optimizer. ...\n",
                "\n",
                "      #TODO:  Compute metrics\n",
                "      acc += ...\n",
                "\n",
                "      train_loss.append(loss.item())\n",
                "\n",
                "      if batch_idx % log_interval == 0:\n",
                "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
                "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
                "              100. * batch_idx / len(train_loader), loss.item()))\n",
                "\n",
                "  avg_acc = 100. * acc / len(train_loader.dataset)\n",
                "\n",
                "  return np.mean(train_loss), avg_acc"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "GfKKO97olwcC",
            "metadata": {
                "id": "GfKKO97olwcC"
            },
            "source": [
                "Complete the function to test the network on a specify epoch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "zJt1fPX0mD4R",
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad() # decorator: avoid computing gradients\n",
                "def test_epoch(\n",
                "    test_loader: torch.utils.data.DataLoader,\n",
                "    network: torch.nn.Module,\n",
                "  ) -> Tuple[float, float]:\n",
                "\n",
                "  # Dectivate the train=True flag inside the model\n",
                "  network.eval()\n",
                "\n",
                "  test_loss = []\n",
                "  acc = 0\n",
                "  for data, target in test_loader:\n",
                "\n",
                "      data, target = data.to(device), target.to(device)\n",
                "      output = network(data)\n",
                "\n",
                "      #TODO: Apply the loss criterion and accumulate the loss\n",
                "      loss = ...\n",
                "      test_loss. ...\n",
                "\n",
                "      #TODO: Compute number of correct predictions in the batch\n",
                "      acc += ...\n",
                "\n",
                "  # TODO: Average accuracy across all correct predictions batches now\n",
                "  test_acc = ...\n",
                "  test_loss = ...\n",
                "\n",
                "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
                "      test_loss, acc, len(test_loader.dataset), test_acc,\n",
                "      ))\n",
                "\n",
                "  return test_loss, test_acc"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "xwOgKpKTmxP_",
            "metadata": {
                "id": "xwOgKpKTmxP_"
            },
            "source": [
                "Finally, run the train/test loops and complete the code so it logs their respective metrics to W&B each epoch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eUNX3Os1VnLe",
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "\n",
                "# TODO: Create the network\n",
                "network = ...\n",
                "\n",
                "optimizer = torch.optim.RMSprop(network.parameters(), lr=hparams['learning_rate'])\n",
                "criterion = nn.NLLLoss(reduction='mean')\n",
                "\n",
                "for epoch in range(hparams['num_epochs']):\n",
                "\n",
                "    # TODO: Compute & log the average training loss and accuracy for the current epoch\n",
                "    train_loss, train_acc = ...\n",
                "\n",
                "    # TODO: Compute & log the average training loss and accuracy for the current epoch\n",
                "    test_loss, test_acc = ...\n",
                "\n",
                "    wandb.log({\n",
                "        \"epoch\": epoch, ## \"epoch\": ...,\n",
                "        \"train/loss\": train_loss, ## \"train/loss\": ...,\n",
                "        \"train/accuracy\": train_acc, ## \"train/accuracy\": ...,\n",
                "        \"test/loss\": test_loss, ## \"test/los\": ...,\n",
                "        \"test/accuracy\": test_acc, ## \"test/accuracy\": ...,\n",
                "    })"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "oPLpf6E4oxGq",
            "metadata": {
                "id": "oPLpf6E4oxGq"
            },
            "source": [
                "### 11) Logging Predictions\n",
                "\n",
                "Now that we have trained our network, let's visualize its performance by logging a confusion matrix to W&B."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "VQbYP2iNoxpK",
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad()\n",
                "def get_all_predictions(\n",
                "    test_loader: torch.utils.data.DataLoader,\n",
                "    network: torch.nn.Module,\n",
                "    device: torch.device,\n",
                ") -> Tuple[List[int], List[int]]:\n",
                "    \"\"\"\n",
                "    Collect all predictions and ground truth labels from the test set.\n",
                "\n",
                "    Returns:\n",
                "    --------\n",
                "    all_preds: List[int]\n",
                "        List of predicted class indices\n",
                "    all_labels: List[int]\n",
                "        List of ground truth class indices\n",
                "    \"\"\"\n",
                "    network.eval()\n",
                "\n",
                "    all_preds = []\n",
                "    all_labels = []\n",
                "\n",
                "    for data, label in test_loader:\n",
                "        data = data.to(device)\n",
                "        output = network(data)\n",
                "\n",
                "        # TODO: Get predicted class indices (hint: use argmax)\n",
                "        preds = ...\n",
                "\n",
                "        all_preds.append(preds)\n",
                "        all_labels.append(label)\n",
                "\n",
                "    all_preds = torch.cat(all_preds)\n",
                "    all_labels = torch.cat(all_labels)\n",
                "\n",
                "    return all_preds.numpy(), all_labels.numpy()\n",
                "\n",
                "# Collect predictions and labels\n",
                "all_preds, all_labels = get_all_predictions(test_loader, network, device)\n",
                "\n",
                "# Define class names for MNIST (digits 0-9)\n",
                "class_names = [str(i) for i in range(10)]\n",
                "\n",
                "# TODO: Log the confusion matrix to W&B as 'test/conf_matrix'\n",
                "# Hint: use wandb.plot.confusion_matrix with the collected predictions and labels\n",
                "run.log({ ... })\n",
                "\n",
                "print(\"Confusion matrix logged to W&B!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d1e668c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remember to finish you run once you are done\n",
                "wandb.finish()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "Bex3YZOnA4VK",
            "metadata": {
                "id": "Bex3YZOnA4VK"
            },
            "source": [
                "## PART 3: Sweeps Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c4276a9",
            "metadata": {
                "id": "6c4276a9"
            },
            "source": [
                "A Sweep in Weights & Biases is an automated hyperparameter search system that runs many training trials with different hyperparameter choices, collects their metrics, and helps you find the best configuration.\n",
                "\n",
                "Check the Sweeps documentation for further details:\n",
                "\n",
                "https://docs.wandb.ai/guides/sweeps"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "54b1e563",
            "metadata": {
                "id": "54b1e563"
            },
            "source": [
                "First we need to define the sweeps configuration. This will alow us to define which metric we want to check, which parameters we want to search, and which searching method to use.\n",
                "\n",
                "Try:\n",
                "\n",
                "-   random method\n",
                "\n",
                "-   we want to maximize the test/acc\n",
                "\n",
                "-   learning rate 1e-4, 1e-3, 1e-2\n",
                "\n",
                "-   batch size 32,64,128\n",
                "\n",
                "-   num_out_fmaps 6,8,16\n",
                "\n",
                "-   num_out_fmaps_2 16,32\n",
                "\n",
                "-   optimizers adam, sgd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b6c7b1d6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Define the sweep configuration dictionary below.\n",
                "sweep_config = { ... }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "46c1d054",
            "metadata": {
                "id": "46c1d054"
            },
            "source": [
                "With that we can now define our Sweep training based on our configuration file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "yz1ctI1FA6Sh",
            "metadata": {},
            "outputs": [],
            "source": [
                "def sweep_train():\n",
                "    # Each sweep run gets its own wandb.init context\n",
                "    with wandb.init(project=PROJECT, config=sweep_config[\"parameters\"]) as run_local:\n",
                "        config = wandb.config\n",
                "\n",
                "        # Build hyperparams dict for the model/training (keep other defaults from hparams)\n",
                "        local_hparams = dict(\n",
                "            kernel_size=hparams.get(\"kernel_size\",5),\n",
                "            num_inp_channels=hparams.get(\"num_inp_channels\", 1),\n",
                "            num_out_fmaps_1=int(config.num_out_fmaps_1),\n",
                "            num_out_fmaps_2=int(config.num_out_fmaps_2),\n",
                "            num_classes=hparams.get(\"num_classes\", 10),\n",
                "            batch_size=int(config.batch_size),\n",
                "            num_epochs=hparams.get(\"num_epochs\",5),\n",
                "            test_batch_size=hparams.get(\"test_batch_size\", config.batch_size),\n",
                "            learning_rate=float(config.learning_rate),\n",
                "            log_interval=hparams.get(\"log_interval\", 100),\n",
                "        )\n",
                "\n",
                "\n",
                "        # deterministically sample 10k train examples\n",
                "        seed = int(hparams.get(\"seed\", 42))\n",
                "        g = torch.Generator()\n",
                "        g.manual_seed(seed)\n",
                "        num_samples = 10000\n",
                "        total = len(mnist_trainset)\n",
                "        selected_indices = torch.randperm(total, generator=g)[:num_samples].tolist()\n",
                "        subset_train = torch.utils.data.Subset(mnist_trainset, selected_indices)\n",
                "\n",
                "        train_loader_local = torch.utils.data.DataLoader(\n",
                "            subset_train,\n",
                "            batch_size=local_hparams[\"batch_size\"],\n",
                "            shuffle=False,\n",
                "            drop_last=True,\n",
                "        )\n",
                "        test_loader_local = torch.utils.data.DataLoader(\n",
                "            mnist_testset,\n",
                "            batch_size=local_hparams[\"test_batch_size\"],\n",
                "            shuffle=False,\n",
                "            drop_last=False,\n",
                "        )\n",
                "\n",
                "        # Create model and move to device\n",
                "        network_local = PseudoLeNet(local_hparams)\n",
                "        network_local.to(device)\n",
                "\n",
                "        # Optimizer selection\n",
                "        if config.optimizer == \"adam\":\n",
                "            optimizer_local = torch.optim.Adam(network_local.parameters(), lr=local_hparams[\"learning_rate\"])\n",
                "        else:\n",
                "            optimizer_local = torch.optim.SGD(network_local.parameters(), lr=local_hparams[\"learning_rate\"])\n",
                "\n",
                "        criterion_local = nn.NLLLoss(reduction=\"mean\")\n",
                "\n",
                "        best_test_acc = 0.0\n",
                "        # train / eval loop (train_epoch/test_epoch use the global name `epoch` when printing;\n",
                "        # ensure it exists in globals so the existing function works as-is)\n",
                "        for ep in range(local_hparams[\"num_epochs\"]):\n",
                "            # expose epoch as a global so train_epoch's print works\n",
                "            globals()[\"epoch\"] = ep\n",
                "\n",
                "            train_loss, train_acc = train_epoch(\n",
                "                train_loader_local,\n",
                "                network_local,\n",
                "                optimizer_local,\n",
                "                criterion_local,\n",
                "                local_hparams[\"log_interval\"],\n",
                "            )\n",
                "\n",
                "            test_loss, test_acc = test_epoch(test_loader_local, network_local)\n",
                "\n",
                "            all_preds, all_labels = get_all_predictions(test_loader_local, network_local, device)\n",
                "\n",
                "            # Define class names for MNIST (digits 0-9)\n",
                "            class_names = [str(i) for i in range(10)]\n",
                "\n",
                "            # TODO: Log the confusion matrix to W&B as 'test/conf_matrix'\n",
                "            # Hint: use wandb.plot.confusion_matrix with the collected predictions and labels\n",
                "\n",
                "            # Log metrics to W&B\n",
                "            wandb.log(\n",
                "                {\n",
                "                    \"epoch\": ep,\n",
                "                    \"train/loss\": float(train_loss),\n",
                "                    \"train/acc\": float(train_acc),\n",
                "                    \"test/loss\": float(test_loss),\n",
                "                    \"test/acc\": float(test_acc),\n",
                "                }\n",
                "            )\n",
                "\n",
                "            # Optionally save best model artifact\n",
                "            if test_acc > best_test_acc:\n",
                "                best_test_acc = test_acc\n",
                "                # Save checkpoint locally and upload as artifact\n",
                "                ckpt_path = f\"best_model_ep{ep:02d}_acc{test_acc:.2f}.pt\"\n",
                "                torch.save(network_local.state_dict(), ckpt_path)\n",
                "                wandb.save(ckpt_path)\n",
                "\n",
                "        # context manager will finish the run"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "29c7366f",
            "metadata": {
                "id": "29c7366f"
            },
            "source": [
                "Now we have to initialize our Sweep. This will return a sweep id that will be used to create the agents responsibles for the trainings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34a74f0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "sweep_id = wandb.sweep(sweep_config, project=PROJECT)\n",
                "sweep_id"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee730098",
            "metadata": {
                "id": "ee730098"
            },
            "source": [
                "You can now enter in the provided link to check the Sweeps status."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9a08d8fe",
            "metadata": {
                "id": "9a08d8fe"
            },
            "source": [
                "Finally, we need to initalize the agent responsible to launch the trains. Then you can go back to the Sweeps URL and see the magic!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a474f4ed",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "#TODO: Start the agent to run the sweep. Select only 10 runs to limit the time.\n",
                "wandb.agent( ..., function=..., count=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c247fd0d",
            "metadata": {
                "id": "c247fd0d"
            },
            "source": [
                "The good thing of using Sweeps is that they allow to create agents in multiple machines at the same time. You only need the Sweeps ID and call the agent in a different machine and the agents will handle everything."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "_YUyjE4WMHOr",
            "metadata": {
                "id": "_YUyjE4WMHOr"
            },
            "source": [
                "If you go the generated Sweeps webpage you will see something like this:\n",
                "\n",
                "![W&B Sweeps \u2013 exemple](https://raw.githubusercontent.com/telecombcn-dl/labs-all/main/labs/wandb/img/wandb_sweeps.png)\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "xEpfmFdJMqgj",
            "metadata": {
                "id": "xEpfmFdJMqgj"
            },
            "source": [
                "## Main Panels in the *W&B Sweep Workspace*\n",
                "\n",
                "## Sidebar (Runs)\n",
                "\n",
                "* List of runs with colors; toggle visibility to focus comparisons.\n",
                "\n",
                "### 1) **test/acc vs. created** (scatter)\n",
                "\n",
                "* X: creation time, Y: test accuracy. Reveals time trends and outliers.\n",
                "\n",
                "### 2) **Parameter importance (w.r.t. test/acc)**\n",
                "\n",
                "* Bars show influence of each hyperparameter; correlation indicates direction (positive/negative effect on accuracy).\n",
                "\n",
                "### 3) **Parallel coordinates**\n",
                "\n",
                "* Each line is a run; axes are hyperparameters/metrics; color encodes performance. Highlights combinations associated with better results.\n",
                "\n",
                "### 4) **Confusion Matrix Curve**\n",
                "\n",
                "* Compact per-class confusion across runs. Rows = actual, columns = predicted. Identifies classes with frequent misclassification.\n",
                "\n",
                "### 5) **test/loss** (curve)\n",
                "\n",
                "* Loss over steps/epochs per run. Lower and stable indicates better convergence.\n",
                "\n",
                "### 6) **test/acc** (curve)\n",
                "\n",
                "* Accuracy over steps/epochs per run. Shows learning progress and final performance ceiling.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "92c75448",
            "metadata": {
                "id": "92c75448"
            },
            "source": [
                "## Conclusions\n",
                "\n",
                "- Summary of W&B usage\n",
                "    - Demonstrated W&B core workflow: install, login, init runs, and finish runs.\n",
                "    - Showed how to log diverse data types: scalars, images, matrices (heatmaps/histograms/tables), confusion matrices, and files/artifacts.\n",
                "    - Illustrated project/run organization and how metadata (config, tags, notes) is captured for reproducibility and searchability.\n",
                "\n",
                "- W&B capabilities highlighted\n",
                "    - Real\u2011time charts and dashboards (Charts, Panels) for interactive inspection and comparison of metrics across runs.\n",
                "    - Artifacts and files for versioned storage of checkpoints, datasets, and auxiliary outputs.\n",
                "    - Confusion matrix and specialized plots (wandb.plot) to inspect model predictions and per\u2011class behavior.\n",
                "    - Sweeps + agents to automate hyperparameter search at scale (random/Bayes/grid strategies, distributed agents).\n",
                "\n",
                "- Reproducibility & collaboration\n",
                "    - Configs, tags, and notes recorded with runs provide a canonical experiment record.\n",
                "    - Artifacts enable exact restoration of models and datasets and preserve lineage between versions.\n",
                "    - Project and Runs views plus reports make it easy to share results and collaborate across teams.\n",
                "\n",
                "- Recommended W&B\u2011centric next steps\n",
                "    - Convert best checkpoints into W&B artifacts and attach descriptive metadata (hyperparams, dataset hash, training script commit).\n",
                "    - Build reusable dashboards/reports that surface key comparisons (per\u2011class metrics, training curves, top artifacts).\n",
                "    - Expand Sweep strategy (e.g., Bayesian sweeps), and use agent orchestration across machines for parallel search.\n",
                "    - Enable alerts, monitor system metrics, and integrate W&B with CI/GitHub to link experiments to code commits and PRs.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "smpl",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
